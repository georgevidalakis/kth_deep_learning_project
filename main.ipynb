{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzA4wZLlOZJQ",
        "outputId": "0187aea4-d677-48f7-c3b9-433e75568e80"
      },
      "outputs": [],
      "source": [
        "# !unzip drive/MyDrive/Pets-data/images.zip\n",
        "# !cp -r drive/MyDrive/Pets-data/annotations .\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G05VSG-WExN-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "from typing import Tuple, List\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from pydantic import BaseModel\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define constants\n",
        "\n",
        "CONFIG_FILE_PATH = 'config.yaml'\n",
        "IMAGE_COL_IDX = 0\n",
        "CLASS_ID_COL_IDX = 1\n",
        "SPECIES_COL_IDX = 2\n",
        "POSSIBLE_NUM_CLASSES = {2, 37}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AdamOptimizerConfig(BaseModel):\n",
        "    lr: float\n",
        "    weight_decay: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config(BaseModel):\n",
        "    device: str\n",
        "    num_classes: int\n",
        "    batch_size: int\n",
        "    max_num_epochs: int\n",
        "    patience: int\n",
        "    adam_optimizer_config: AdamOptimizerConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(CONFIG_FILE_PATH, encoding='utf-8') as f:\n",
        "    config_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
        "\n",
        "config = Config.model_validate(config_dict)\n",
        "\n",
        "assert config.num_classes in POSSIBLE_NUM_CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3bs_rvb7HsqY"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, filenames: List[str], labels: List[int]) -> None:\n",
        "        self.filenames = filenames\n",
        "        self.labels = labels\n",
        "        self.transformation = torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        image = Image.open(os.path.join('images', f'{self.filenames[idx]}.jpg')).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        transformed_img = self.transformation(image)\n",
        "\n",
        "        return transformed_img.to(config.device), torch.tensor(label).to(config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VWB1d993Kmmp"
      },
      "outputs": [],
      "source": [
        "def get_image_names_and_labels(annotations_file_path: str, num_classes: int) -> Tuple[List[str], List[int]]:\n",
        "    filenames: List[str] = []\n",
        "    labels: List[int] = []\n",
        "\n",
        "    with open(annotations_file_path, encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    label_col_idx = SPECIES_COL_IDX if num_classes == 2 else CLASS_ID_COL_IDX\n",
        "\n",
        "    for line in lines:\n",
        "        line_split = line.split()\n",
        "        filenames.append(line_split[IMAGE_COL_IDX])\n",
        "        labels.append(int(line_split[label_col_idx]) - 1)\n",
        "\n",
        "    return filenames, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nopF1mMoExN_"
      },
      "outputs": [],
      "source": [
        "def get_pretrained_model_with_trainable_last_layer() -> nn.Module:\n",
        "    model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=config.num_classes)\n",
        "\n",
        "    return model.to(config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model_accuracy(model: nn.Module, data_loader: DataLoader) -> float:\n",
        "    correct_predictions_cnt = 0\n",
        "    total_predictions_cnt = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc='Computing accuracy'):\n",
        "            outputs = model(inputs)\n",
        "            correct_predictions_cnt += (torch.argmax(outputs, axis=1) == labels).sum()\n",
        "            total_predictions_cnt += len(outputs)\n",
        "    return correct_predictions_cnt / total_predictions_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_single_epoch(model: nn.Module, train_data_loader: DataLoader, criterion: nn.Module, optimizer: torch.optim.Optimizer) -> float:\n",
        "    model.train()\n",
        "    train_loss_sum = 0.0\n",
        "    train_samples_cnt = 0\n",
        "    for inputs, labels in tqdm(train_data_loader, desc='Training model'):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_sum += loss.item() * len(outputs)\n",
        "        train_samples_cnt += len(outputs)\n",
        "    return train_loss_sum / train_samples_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_checkpoint(model: nn.Module, optimizer: torch.optim.Optimizer) -> Tuple[nn.Module, torch.optim.Optimizer]:\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, 'checkpoint.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_checkpoint(model: nn.Module, optimizer: torch.optim.Optimizer) -> None:\n",
        "    checkpoint = torch.load('checkpoint.pt')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l_Z-eIVoExOB"
      },
      "outputs": [],
      "source": [
        "filenames_trainval, labels_trainval = get_image_names_and_labels('annotations/trainval.txt', num_classes=config.num_classes)\n",
        "filenames_test, labels_test = get_image_names_and_labels('annotations/test.txt', num_classes=config.num_classes)\n",
        "filenames_train, filenames_val, labels_train, labels_val = train_test_split(filenames_trainval, labels_trainval, test_size=0.2, stratify=labels_trainval)\n",
        "\n",
        "dataset_train = ImageDataset(filenames_train, labels_train)\n",
        "dataset_val = ImageDataset(filenames_val, labels_val)\n",
        "dataset_test = ImageDataset(filenames_test, labels_test)\n",
        "\n",
        "train_data_loader = DataLoader(dataset_train, batch_size=config.batch_size, shuffle=True)\n",
        "val_data_loader = DataLoader(dataset_val, batch_size=config.batch_size, shuffle=False)\n",
        "test_data_loader = DataLoader(dataset_test, batch_size=config.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "EYVA1JYkN0ZB",
        "outputId": "f81b8438-c34d-48d8-f166-a3be7ca2c2e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:17<00:00,  5.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.19382216032270505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:04<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 97.69% (new best)\n",
            "Checkpoint saved\n",
            "\n",
            "Epoch #1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:15<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.0643600793150456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:03<00:00,  6.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 99.18% (new best)\n",
            "Checkpoint saved\n",
            "\n",
            "Epoch #2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:14<00:00,  6.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.05387528233594545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:03<00:00,  6.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 99.18% (worse than 99.18% of epoch 1)\n",
            "\n",
            "Epoch #3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:14<00:00,  6.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.049693096024186714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:02<00:00,  8.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 99.18% (worse than 99.18% of epoch 1)\n",
            "\n",
            "Epoch #4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:12<00:00,  7.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.04158833804135413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:02<00:00,  8.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 99.05% (worse than 99.18% of epoch 1)\n",
            "\n",
            "Epoch #5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:12<00:00,  7.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.04413732932880521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:03<00:00,  7.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 99.18% (worse than 99.18% of epoch 1)\n",
            "\n",
            "Epoch #6:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:12<00:00,  7.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.03366809609123384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:03<00:00,  7.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 99.32% (new best)\n",
            "Checkpoint saved\n",
            "\n",
            "Epoch #7:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:13<00:00,  7.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.03269082910770996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:03<00:00,  7.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 98.91% (worse than 99.32% of epoch 6)\n",
            "\n",
            "Epoch #8:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:13<00:00,  7.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.030781664412959642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:03<00:00,  7.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 99.18% (worse than 99.32% of epoch 6)\n",
            "\n",
            "Epoch #9:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training model: 100%|██████████| 92/92 [00:12<00:00,  7.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.0310769115584781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 23/23 [00:02<00:00,  7.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 98.78% (worse than 99.32% of epoch 6)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = get_pretrained_model_with_trainable_last_layer()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config.adam_optimizer_config.lr, weight_decay=config.adam_optimizer_config.weight_decay)\n",
        "\n",
        "max_val_accuracy = float('-inf')\n",
        "argmax_epoch = -1\n",
        "\n",
        "for epoch in range(config.max_num_epochs):\n",
        "    print(f'Epoch #{epoch}:')\n",
        "    train_loss = train_single_epoch(model, train_data_loader, criterion, optimizer)\n",
        "    print(f'Train loss: {train_loss}')\n",
        "    val_accuracy = get_model_accuracy(model, val_data_loader)\n",
        "    if val_accuracy > max_val_accuracy:\n",
        "        print(f'Validation accuracy: {100 * val_accuracy:.2f}% (new best)')\n",
        "        max_val_accuracy = val_accuracy\n",
        "        argmax_epoch = epoch\n",
        "        save_checkpoint(model, optimizer)\n",
        "        print('Checkpoint saved')\n",
        "    else:\n",
        "        print(f'Validation accuracy: {100 * val_accuracy:.2f}% (worse than {100 * max_val_accuracy:.2f}% of epoch {argmax_epoch})')\n",
        "        if epoch > argmax_epoch + config.patience:\n",
        "            print(f'Early stopping')\n",
        "            break\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing accuracy: 100%|██████████| 115/115 [00:16<00:00,  6.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 99.26%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "load_checkpoint(model, optimizer)\n",
        "print('Checkpoint loaded')\n",
        "\n",
        "test_accuracy = get_model_accuracy(model, test_data_loader)\n",
        "\n",
        "print(f'Test accuracy: {100 * test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
