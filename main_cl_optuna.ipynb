{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G05VSG-WExN-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yaml\n",
        "from typing import Tuple, List, Optional\n",
        "\n",
        "import torch\n",
        "import optuna\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from pydantic import BaseModel\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mw2iUZkZXMW3"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "\n",
        "IMAGE_COL_IDX = 0\n",
        "CLASS_ID_COL_IDX = 1\n",
        "SPECIES_COL_IDX = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V_BHkWLlXMW3"
      },
      "outputs": [],
      "source": [
        "class AdamOptimizerConfig(BaseModel):\n",
        "    lr: float\n",
        "    weight_decay: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LastLayerTrainingConfig(BaseModel):\n",
        "    unfreeze_epoch: int\n",
        "    lr: float\n",
        "    weight_decay: float\n",
        "    use_train_mode: bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XkhfRZxKXMW4"
      },
      "outputs": [],
      "source": [
        "class Config(BaseModel):\n",
        "    device: str\n",
        "    num_classes: int\n",
        "    batch_size: int\n",
        "    max_num_epochs: int\n",
        "    patience: int\n",
        "    last_layers_training_configs: List[LastLayerTrainingConfig]\n",
        "    labeled_data_ratio: float\n",
        "    use_pseudo_labeling: bool\n",
        "    cl_delta: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3bs_rvb7HsqY"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, filenames: List[str], labels: List[int], transformations, device: str) -> None:\n",
        "        # self.filenames = filenames\n",
        "        self.labels = torch.tensor(labels).to(device)\n",
        "        init_transformation, self.final_transformation = transformations\n",
        "        self.partially_transformed_images = torch.stack([\n",
        "            init_transformation(Image.open(os.path.join('images', f'{filename}.jpg')).convert('RGB'))\n",
        "            for filename in filenames\n",
        "        ]).to(device)\n",
        "        # self.device = device\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        partially_transformed_image = self.partially_transformed_images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        transformed_img = self.final_transformation(partially_transformed_image)\n",
        "\n",
        "        return transformed_img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnlabeledImageDataset(Dataset):\n",
        "    def __init__(self, filenames: List[str], transformations, device: str) -> None:\n",
        "        self.filenames = filenames\n",
        "        init_transformation, self.final_transformation = transformations\n",
        "        self.device = device\n",
        "        self.partially_transformed_images = [\n",
        "            init_transformation(Image.open(os.path.join('images', f'{filename}.jpg')).convert('RGB'))\n",
        "            for filename in filenames\n",
        "        ]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        partially_transformed_image = self.partially_transformed_images[idx]\n",
        "\n",
        "        transformed_img = self.final_transformation(partially_transformed_image)\n",
        "\n",
        "        return transformed_img.to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VWB1d993Kmmp"
      },
      "outputs": [],
      "source": [
        "def get_image_names_and_labels(annotations_file_path: str, num_classes: int) -> Tuple[List[str], List[int]]:\n",
        "    filenames: List[str] = []\n",
        "    labels: List[int] = []\n",
        "\n",
        "    with open(annotations_file_path, encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    label_col_idx = SPECIES_COL_IDX if num_classes == 2 else CLASS_ID_COL_IDX\n",
        "\n",
        "    for line in lines:\n",
        "        line_split = line.split()\n",
        "        filenames.append(line_split[IMAGE_COL_IDX])\n",
        "        labels.append(int(line_split[label_col_idx]) - 1)\n",
        "\n",
        "    return filenames, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_pretrained_model_and_model_trainable_layers(num_classes: int, device: str) -> nn.Module:\n",
        "    model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model_trainable_layers = [\n",
        "        layer\n",
        "        for layer in model.modules()\n",
        "        if (not isinstance(layer, torchvision.models.resnet.ResNet) and\n",
        "            not isinstance(layer, torchvision.models.resnet.BasicBlock) and\n",
        "            not isinstance(layer, nn.Sequential) and not isinstance(layer, nn.Sequential) and\n",
        "            len(list(layer.parameters())) > 0)\n",
        "    ]\n",
        "\n",
        "    return model.to(device), model_trainable_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PPeg-qfgXMW6"
      },
      "outputs": [],
      "source": [
        "def get_model_accuracy(model: nn.Module, data_loader: DataLoader) -> float:\n",
        "    correct_predictions_cnt = 0\n",
        "    total_predictions_cnt = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # for inputs, labels in tqdm(data_loader, desc='Computing accuracy'):\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            correct_predictions_cnt += (torch.argmax(outputs, axis=1) == labels).sum()\n",
        "            total_predictions_cnt += len(outputs)\n",
        "    return correct_predictions_cnt / total_predictions_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_single_epoch(\n",
        "        model: nn.Module,\n",
        "        model_trainable_layers: List[nn.Module],\n",
        "        train_data_loader: DataLoader,\n",
        "        criterion: nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        last_layers_training_configs: List[LastLayerTrainingConfig],\n",
        "        epoch: int,\n",
        "        ) -> float:\n",
        "    model.eval()\n",
        "    for layer_reverse_idx, layer_training_config in enumerate(last_layers_training_configs):\n",
        "        layer = model_trainable_layers[-layer_reverse_idx - 1]\n",
        "        if layer_training_config.unfreeze_epoch <= epoch:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True\n",
        "            if layer_training_config.use_train_mode:\n",
        "                layer.train()\n",
        "        if layer_reverse_idx and layer_training_config.unfreeze_epoch == epoch:\n",
        "            optimizer.add_param_group({\n",
        "                'params': layer.parameters(),\n",
        "                'lr': layer_training_config.lr,\n",
        "                'weight_decay': layer_training_config.weight_decay,\n",
        "            })\n",
        "    train_loss_sum = 0.0\n",
        "    train_samples_cnt = 0\n",
        "    # for inputs, labels in tqdm(train_data_loader, desc='Training model'):\n",
        "    for inputs, labels in train_data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_sum += loss.item() * len(outputs)\n",
        "        train_samples_cnt += len(outputs)\n",
        "    return train_loss_sum / train_samples_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XIdYAijVXMW7"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model: nn.Module, checkpoint_file_path: str) -> None:\n",
        "    checkpoint = {'model_state_dict': model.state_dict()}\n",
        "    torch.save(checkpoint, checkpoint_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "puyQaj1KXMW7"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(model: nn.Module, checkpoint_file_path: str) -> None:\n",
        "    checkpoint = torch.load(checkpoint_file_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_filenames_and_labels_split(\n",
        "        num_classes: int,\n",
        "        use_pseudo_labeling: bool,\n",
        "        labeled_data_ratio: float,\n",
        "        ) -> Tuple[Tuple[List[str], List[int]], Tuple[List[str], List[int]], Tuple[List[str], List[int]], Optional[List[str]]]:\n",
        "    filenames_trainval, labels_trainval = get_image_names_and_labels('annotations/trainval.txt', num_classes=num_classes)\n",
        "    filenames_test, labels_test = get_image_names_and_labels('annotations/test.txt', num_classes=num_classes)\n",
        "    filenames_train, filenames_val, labels_train, labels_val = train_test_split(\n",
        "        filenames_trainval, labels_trainval, test_size=0.2, stratify=labels_trainval, random_state=42\n",
        "    )\n",
        "\n",
        "    if int(labeled_data_ratio * len(filenames_train)) >= num_classes:\n",
        "        train_size = labeled_data_ratio\n",
        "    else:\n",
        "        train_size = num_classes\n",
        "    labeled_filenames_train, unlabeled_filenames_train, labels_labeled_train, _ = train_test_split(\n",
        "        filenames_train, labels_train, train_size=train_size, stratify=labels_train\n",
        "    )\n",
        "\n",
        "    if not use_pseudo_labeling:\n",
        "        unlabeled_filenames_train = None\n",
        "\n",
        "    return (\n",
        "        (labeled_filenames_train, labels_labeled_train),\n",
        "        (filenames_val, labels_val),\n",
        "        (filenames_test, labels_test),\n",
        "        unlabeled_filenames_train,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_transformations(use_augmentation: bool):\n",
        "    if use_augmentation:\n",
        "        transformations = (\n",
        "            transforms.Compose([\n",
        "                transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
        "                transforms.PILToTensor(),\n",
        "                transforms.ConvertImageDtype(dtype=torch.float),\n",
        "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "                transforms.CenterCrop(size=256),\n",
        "            ]),\n",
        "            transforms.Compose([\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomResizedCrop(size=224),\n",
        "            ]),\n",
        "        )\n",
        "    else:\n",
        "        transformations = (\n",
        "            torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms(),\n",
        "            torch.nn.Identity(),\n",
        "        )\n",
        "    return transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "l_Z-eIVoExOB"
      },
      "outputs": [],
      "source": [
        "def get_labeled_data_loader(filenames: List[str], labels: List[int], use_augmentation: bool, device: str, batch_size: int, shuffle: bool) -> DataLoader:\n",
        "    transformations = get_transformations(use_augmentation)\n",
        "    dataset = ImageDataset(filenames, labels, transformations, device)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_unlabeled_data_loader(filenames: List[str], use_augmentation: bool, device: str, batch_size: int, shuffle: bool) -> DataLoader:\n",
        "    transformations = get_transformations(use_augmentation)\n",
        "    dataset = UnlabeledImageDataset(filenames, transformations, device)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_once_and_get_max_val_accuracy(config: Config, labeled_train_data_loader: DataLoader, val_data_loader: DataLoader, checkpoint_file_path: str) -> float:\n",
        "    model, model_trainable_layers = get_pretrained_model_and_model_trainable_layers(config.num_classes, config.device)\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model_trainable_layers[-1].parameters(),\n",
        "        lr=config.last_layers_training_configs[0].lr,\n",
        "        weight_decay=config.last_layers_training_configs[0].weight_decay,\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    max_val_accuracy = float('-inf')\n",
        "    argmax_epoch = -1\n",
        "\n",
        "    # for epoch in range(config.max_num_epochs):\n",
        "    for epoch in tqdm(list(range(config.max_num_epochs))):\n",
        "        # print(f'Epoch #{epoch}:')\n",
        "        train_loss = train_single_epoch(\n",
        "            model, model_trainable_layers, labeled_train_data_loader, criterion, optimizer, config.last_layers_training_configs, epoch\n",
        "        )\n",
        "        # print(f'Train loss: {train_loss}')\n",
        "        val_accuracy = get_model_accuracy(model, val_data_loader)\n",
        "        if val_accuracy > max_val_accuracy:\n",
        "            # print(f'Validation accuracy: {100 * val_accuracy:.2f}% (new best)')\n",
        "            max_val_accuracy = val_accuracy\n",
        "            argmax_epoch = epoch\n",
        "            save_checkpoint(model, checkpoint_file_path)\n",
        "            # print('Checkpoint saved')\n",
        "        else:\n",
        "            # print(f'Validation accuracy: {100 * val_accuracy:.2f}% (worse than {100 * max_val_accuracy:.2f}% of epoch {argmax_epoch})')\n",
        "            if epoch > argmax_epoch + config.patience:\n",
        "                # print(f'Early stopping')\n",
        "                break\n",
        "        # print()\n",
        "\n",
        "    return max_val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_with_curriculum_learning_and_get_max_accuracy_and_model(config: Config) -> Tuple[float, nn.Module]:\n",
        "    (\n",
        "        (labeled_filenames_train, labels_labeled_train),\n",
        "        (filenames_val, labels_val),\n",
        "        (filenames_test, labels_test),\n",
        "        unlabeled_filenames_train,\n",
        "    ) = get_filenames_and_labels_split(config.num_classes, config.use_pseudo_labeling, config.labeled_data_ratio)\n",
        "\n",
        "    labeled_train_data_loader = get_labeled_data_loader(\n",
        "        labeled_filenames_train, labels_labeled_train, use_augmentation=True, device=config.device, batch_size=config.batch_size, shuffle=True\n",
        "    )\n",
        "    val_data_loader = get_labeled_data_loader(\n",
        "        filenames_val, labels_val, use_augmentation=False, device=config.device, batch_size=config.batch_size, shuffle=False\n",
        "    )\n",
        "    test_data_loader = get_labeled_data_loader(\n",
        "        filenames_test, labels_test, use_augmentation=False, device=config.device, batch_size=config.batch_size, shuffle=False\n",
        "    )\n",
        "    if config.use_pseudo_labeling:\n",
        "        unlabeled_train_data_loader = get_unlabeled_data_loader(\n",
        "            unlabeled_filenames_train, use_augmentation=False, device=config.device, batch_size=config.batch_size, shuffle=False\n",
        "        )\n",
        "    else:\n",
        "        unlabeled_train_data_loader = None\n",
        "    \n",
        "    cur_pseudo_labeled_samples_ratio = 0.0\n",
        "\n",
        "    iteration_idx = 0\n",
        "    trial_idx = np.random.randint(0, 1_000_000)\n",
        "\n",
        "    while True:\n",
        "        print(f'Iteration {iteration_idx} (cur_pseudo_labeled_samples_ratio: {cur_pseudo_labeled_samples_ratio})')\n",
        "        # train once and load best model\n",
        "        checkpoint_file_path = os.path.join('checkpoints', f'checkpoint_{trial_idx}_{iteration_idx}.pt')\n",
        "        val_accuracy = train_once_and_get_max_val_accuracy(config, labeled_train_data_loader, val_data_loader, checkpoint_file_path)\n",
        "        print(f'Validation accuracy: {100 * val_accuracy:.2f}%')\n",
        "        model, _ = get_pretrained_model_and_model_trainable_layers(config.num_classes, config.device)\n",
        "        load_checkpoint(model, checkpoint_file_path)\n",
        "        test_accuracy = get_model_accuracy(model, test_data_loader)\n",
        "        print(f'Test accuracy: {100 * test_accuracy:.2f}%')\n",
        "        if not config.use_pseudo_labeling or cur_pseudo_labeled_samples_ratio == 1.0:\n",
        "            return val_accuracy, model\n",
        "        # create pseudo-labels\n",
        "        unlabeled_samples_max_probs_list: List[float] = []\n",
        "        unlabeled_samples_argmax_labels_list: List[int] = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            assert unlabeled_train_data_loader is not None\n",
        "            for inputs in unlabeled_train_data_loader:\n",
        "                outputs = model(inputs)\n",
        "                outputs_probs = torch.softmax(outputs, dim=1)\n",
        "                outputs_max_probs, outputs_argmax_labels = torch.max(outputs_probs, dim=1)\n",
        "                unlabeled_samples_max_probs_list += outputs_max_probs.tolist()\n",
        "                unlabeled_samples_argmax_labels_list += outputs_argmax_labels.tolist()\n",
        "        unlabeled_samples_max_probs = torch.tensor(unlabeled_samples_max_probs_list)\n",
        "        unlabeled_samples_argmax_labels = torch.tensor(unlabeled_samples_argmax_labels_list)\n",
        "        sorted_unlabeled_samples_indices = torch.flip(torch.argsort(unlabeled_samples_max_probs), dims=(0,))\n",
        "        sorted_unlabeled_samples_filenames = [unlabeled_filenames_train[sample_idx] for sample_idx in sorted_unlabeled_samples_indices]\n",
        "        sorted_unlabeled_samples_argmax_labels = unlabeled_samples_argmax_labels[sorted_unlabeled_samples_indices].tolist()\n",
        "        # augment training set\n",
        "        cur_pseudo_labeled_samples_ratio = min(1.0, cur_pseudo_labeled_samples_ratio + config.cl_delta)\n",
        "        cur_pseudo_labeled_samples_cnt = int(cur_pseudo_labeled_samples_ratio * len(unlabeled_filenames_train))\n",
        "        pseudo_labeled_samples_filenames = sorted_unlabeled_samples_filenames[:cur_pseudo_labeled_samples_cnt]\n",
        "        pseudo_labeled_samples_pseudo_labels = sorted_unlabeled_samples_argmax_labels[:cur_pseudo_labeled_samples_cnt]\n",
        "        labeled_train_data_loader = get_labeled_data_loader(\n",
        "            filenames=labeled_filenames_train + pseudo_labeled_samples_filenames,\n",
        "            labels=labels_labeled_train + pseudo_labeled_samples_pseudo_labels,\n",
        "            use_augmentation=True,\n",
        "            device=config.device,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        # next iteration\n",
        "        iteration_idx += 1\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYVA1JYkN0ZB",
        "outputId": "d0ab9637-378d-402f-d24e-a94f19ff11c1"
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial):\n",
        "    # batch_size_exp = trial.suggest_int(\"batch_size_exp\", 3, 5)\n",
        "    batch_size_exp = 4\n",
        "    batch_size = 2 ** batch_size_exp\n",
        "    config = Config(\n",
        "        device='cuda:0',\n",
        "        num_classes=37,\n",
        "        batch_size=batch_size,\n",
        "        max_num_epochs=100,  # 100\n",
        "        patience=10,\n",
        "        last_layers_training_configs=[],\n",
        "        # pseudo-labeling\n",
        "        use_pseudo_labeling=True,\n",
        "        labeled_data_ratio=0.01,\n",
        "        cl_delta=0.2,\n",
        "    )\n",
        "    # last_layer_lr_exp = trial.suggest_float(\"last_layer_lr_exp\", -4.0, -2.0)\n",
        "    # last_layer_weight_decay_exp = trial.suggest_float(\"last_layer_weight_decay_exp\", -4.0, -2.0)\n",
        "    last_layer_lr_exp = -3.862332103325873\n",
        "    last_layer_weight_decay_exp = -2.520447729733064\n",
        "    last_layer_lr = 10.0 ** last_layer_lr_exp\n",
        "    last_layer_weight_decay = 10.0 ** last_layer_weight_decay_exp\n",
        "    config.last_layers_training_configs.append(LastLayerTrainingConfig(\n",
        "        unfreeze_epoch=0,\n",
        "        lr=last_layer_lr,\n",
        "        weight_decay=last_layer_weight_decay,\n",
        "        use_train_mode=True,\n",
        "    ))\n",
        "    # second_last_layer_unfreeze_epoch = trial.suggest_int(\"second_last_layer_unfreeze_epoch\", 1, 10)\n",
        "    # second_last_layer_lr_exp = trial.suggest_float(\"second_last_layer_lr_exp\", -5.0, -1.0)\n",
        "    # second_last_layer_weight_decay_exp = trial.suggest_float(\"second_last_layer_weight_decay_exp\", -5.0, -1.0)\n",
        "    second_last_layer_unfreeze_epoch = 6\n",
        "    second_last_layer_lr_exp = -3.7985851526938648\n",
        "    second_last_layer_weight_decay_exp = -2.218563662514852\n",
        "    second_last_layer_lr = 10.0 ** second_last_layer_lr_exp\n",
        "    second_last_layer_weight_decay = 10.0 ** second_last_layer_weight_decay_exp\n",
        "    config.last_layers_training_configs.append(LastLayerTrainingConfig(\n",
        "        unfreeze_epoch=second_last_layer_unfreeze_epoch,\n",
        "        lr=second_last_layer_lr,\n",
        "        weight_decay=second_last_layer_weight_decay,\n",
        "        use_train_mode=True,\n",
        "    ))\n",
        "    # third_last_layer_unfreeze_epoch = trial.suggest_int(\"third_last_layer_unfreeze_epoch\", second_last_layer_unfreeze_epoch, 15)\n",
        "    # third_last_layer_lr_exp = trial.suggest_float(\"third_last_layer_lr_exp\", -5.0, -1.0)\n",
        "    # third_last_layer_weight_decay_exp = trial.suggest_float(\"third_last_layer_weight_decay_exp\", -5.0, -1.0)\n",
        "    third_last_layer_unfreeze_epoch = 6\n",
        "    third_last_layer_lr_exp = -3.636363070796339\n",
        "    third_last_layer_weight_decay_exp = -1.9693380362468311\n",
        "    third_last_layer_lr = 10.0 ** third_last_layer_lr_exp\n",
        "    third_last_layer_weight_decay = 10.0 ** third_last_layer_weight_decay_exp\n",
        "    config.last_layers_training_configs.append(LastLayerTrainingConfig(\n",
        "        unfreeze_epoch=third_last_layer_unfreeze_epoch,\n",
        "        lr=third_last_layer_lr,\n",
        "        weight_decay=third_last_layer_weight_decay,\n",
        "        use_train_mode=True,\n",
        "    ))\n",
        "    val_accuracy, model = train_with_curriculum_learning_and_get_max_accuracy_and_model(config)\n",
        "    return val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 20:52:55,749] A new study created in memory with name: no-name-f42b6c2c-f51c-4934-9a60-9a8117bc4090\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 48/100 [00:32<00:34,  1.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 70.38%\n",
            "Test accuracy: 65.58%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [00:42<01:25,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 70.92%\n",
            "Test accuracy: 67.84%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 23/100 [00:43<02:25,  1.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 69.16%\n",
            "Test accuracy: 65.74%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 19/100 [00:48<03:24,  2.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 68.34%\n",
            "Test accuracy: 66.67%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [01:44<03:23,  3.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 69.29%\n",
            "Test accuracy: 69.09%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 17/100 [01:03<05:12,  3.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 70.11%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 21:00:05,786] Trial 0 finished with value: 0.7010869979858398 and parameters: {}. Best is trial 0 with value: 0.7010869979858398.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 69.58%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 61/100 [00:41<00:26,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.03%\n",
            "Test accuracy: 65.63%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [00:46<01:22,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.54%\n",
            "Test accuracy: 64.35%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [01:02<02:06,  1.89s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.67%\n",
            "Test accuracy: 61.13%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [01:02<03:08,  2.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.40%\n",
            "Test accuracy: 62.17%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 28/100 [01:26<03:43,  3.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.08%\n",
            "Test accuracy: 61.95%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 31/100 [01:54<04:13,  3.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.67%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 21:08:28,604] Trial 1 finished with value: 0.64673912525177 and parameters: {}. Best is trial 0 with value: 0.7010869979858398.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 62.14%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:28<00:39,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 62.77%\n",
            "Test accuracy: 59.01%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 23/100 [00:30<01:40,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 62.91%\n",
            "Test accuracy: 61.71%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [00:45<02:24,  1.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 62.36%\n",
            "Test accuracy: 61.52%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [01:04<03:03,  2.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.08%\n",
            "Test accuracy: 63.83%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 16/100 [00:50<04:24,  3.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.44%\n",
            "Test accuracy: 65.49%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [01:32<04:37,  3.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 69.29%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 21:15:12,134] Trial 2 finished with value: 0.6929348111152649 and parameters: {}. Best is trial 0 with value: 0.7010869979858398.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 66.94%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 41/100 [00:28<00:40,  1.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 62.91%\n",
            "Test accuracy: 61.68%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [00:35<01:35,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.49%\n",
            "Test accuracy: 64.24%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [00:45<02:24,  1.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.44%\n",
            "Test accuracy: 64.81%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [01:07<03:01,  2.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.35%\n",
            "Test accuracy: 65.22%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 22/100 [01:08<04:04,  3.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.98%\n",
            "Test accuracy: 67.24%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 19/100 [01:11<05:04,  3.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 68.34%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 21:21:55,817] Trial 3 finished with value: 0.6834239363670349 and parameters: {}. Best is trial 0 with value: 0.7010869979858398.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 66.34%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 50/100 [00:34<00:34,  1.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 62.77%\n",
            "Test accuracy: 63.83%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [00:33<01:36,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 67.80%\n",
            "Test accuracy: 68.14%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [00:56<02:12,  1.89s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 70.24%\n",
            "Test accuracy: 68.14%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [01:30<02:40,  2.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 73.10%\n",
            "Test accuracy: 70.26%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 40/100 [02:02<03:04,  3.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 73.23%\n",
            "Test accuracy: 70.18%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 28/100 [01:42<04:24,  3.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 72.83%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 21:30:45,366] Trial 4 finished with value: 0.72826087474823 and parameters: {}. Best is trial 4 with value: 0.72826087474823.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 70.43%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 59/100 [00:40<00:27,  1.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.71%\n",
            "Test accuracy: 63.97%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [00:33<01:36,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.30%\n",
            "Test accuracy: 63.40%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 44/100 [01:21<01:44,  1.86s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.03%\n",
            "Test accuracy: 64.00%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [01:12<02:57,  2.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 67.39%\n",
            "Test accuracy: 64.08%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 17/100 [00:53<04:21,  3.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 67.66%\n",
            "Test accuracy: 65.19%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [01:32<04:38,  3.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 68.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 21:38:28,992] Trial 5 finished with value: 0.6847826242446899 and parameters: {}. Best is trial 4 with value: 0.72826087474823.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 65.58%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 49/100 [00:33<00:34,  1.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.17%\n",
            "Test accuracy: 64.30%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:32<01:38,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.58%\n",
            "Test accuracy: 64.08%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [00:56<02:12,  1.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.95%\n",
            "Test accuracy: 63.10%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 28/100 [01:10<03:00,  2.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.35%\n",
            "Test accuracy: 63.37%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 19/100 [00:59<04:13,  3.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.08%\n",
            "Test accuracy: 64.49%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [01:36<04:34,  3.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 67.39%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 21:45:48,097] Trial 6 finished with value: 0.6739130616188049 and parameters: {}. Best is trial 4 with value: 0.72826087474823.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 64.79%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 47/100 [00:32<00:36,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 62.50%\n",
            "Test accuracy: 62.61%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:32<01:36,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 60.73%\n",
            "Test accuracy: 61.13%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [01:07<02:00,  1.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 61.68%\n",
            "Test accuracy: 61.35%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [01:25<02:45,  2.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 62.09%\n",
            "Test accuracy: 62.03%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 47/100 [02:24<02:42,  3.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 63.72%\n",
            "Test accuracy: 64.00%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [01:07<05:06,  3.73s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 21:54:26,161] Trial 7 finished with value: 0.645380437374115 and parameters: {}. Best is trial 4 with value: 0.72826087474823.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 63.23%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [00:21<00:49,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 63.59%\n",
            "Test accuracy: 61.87%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 39/100 [00:49<01:17,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 67.66%\n",
            "Test accuracy: 65.06%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 32/100 [01:00<02:07,  1.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.98%\n",
            "Test accuracy: 63.56%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 44/100 [01:48<02:17,  2.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 67.12%\n",
            "Test accuracy: 63.59%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [01:17<03:53,  3.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 69.02%\n",
            "Test accuracy: 66.01%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [01:47<04:22,  3.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 70.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 22:02:55,905] Trial 8 finished with value: 0.70652174949646 and parameters: {}. Best is trial 4 with value: 0.72826087474823.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 67.35%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 47/100 [00:32<00:36,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 63.32%\n",
            "Test accuracy: 62.99%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:32<01:38,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 67.39%\n",
            "Test accuracy: 66.67%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [00:46<02:26,  1.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.67%\n",
            "Test accuracy: 63.21%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [01:27<02:42,  2.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 62.64%\n",
            "Test accuracy: 61.19%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [01:24<03:48,  3.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 61.28%\n",
            "Test accuracy: 61.41%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [02:09<03:59,  3.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 61.28%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 22:11:22,594] Trial 9 finished with value: 0.61277174949646 and parameters: {}. Best is trial 4 with value: 0.72826087474823.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 61.05%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 60/100 [00:40<00:27,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 69.43%\n",
            "Test accuracy: 65.58%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 47/100 [01:00<01:07,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 68.21%\n",
            "Test accuracy: 64.30%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 28/100 [00:53<02:17,  1.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.17%\n",
            "Test accuracy: 63.75%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [01:07<03:03,  2.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.44%\n",
            "Test accuracy: 64.38%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 21/100 [01:06<04:09,  3.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.49%\n",
            "Test accuracy: 62.69%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 17/100 [01:04<05:13,  3.77s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 22:18:51,001] Trial 10 finished with value: 0.654891312122345 and parameters: {}. Best is trial 4 with value: 0.72826087474823.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 63.26%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:29<00:40,  1.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 61.28%\n",
            "Test accuracy: 59.39%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [00:37<01:32,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.13%\n",
            "Test accuracy: 61.52%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 21/100 [00:40<02:32,  1.93s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.85%\n",
            "Test accuracy: 62.99%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [01:05<03:06,  2.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 68.07%\n",
            "Test accuracy: 63.89%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [01:41<03:26,  3.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 68.34%\n",
            "Test accuracy: 64.87%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 19/100 [01:11<05:05,  3.77s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 69.02%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 22:26:07,353] Trial 11 finished with value: 0.6902173757553101 and parameters: {}. Best is trial 4 with value: 0.72826087474823.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 66.97%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 38/100 [00:26<00:43,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 68.89%\n",
            "Test accuracy: 64.51%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 38/100 [00:49<01:20,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 68.34%\n",
            "Test accuracy: 63.18%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [00:49<02:21,  1.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.95%\n",
            "Test accuracy: 63.75%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [01:27<02:42,  2.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.08%\n",
            "Test accuracy: 61.82%\n",
            "\n",
            "Iteration 4 (cur_pseudo_labeled_samples_ratio: 0.8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [01:30<03:40,  3.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.08%\n",
            "Test accuracy: 63.04%\n",
            "\n",
            "Iteration 5 (cur_pseudo_labeled_samples_ratio: 1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 20/100 [01:15<05:00,  3.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 65.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-26 22:33:58,721] Trial 12 finished with value: 0.65625 and parameters: {}. Best is trial 4 with value: 0.72826087474823.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 63.01%\n",
            "Iteration 0 (cur_pseudo_labeled_samples_ratio: 0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 56/100 [00:38<00:30,  1.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 67.80%\n",
            "Test accuracy: 64.54%\n",
            "\n",
            "Iteration 1 (cur_pseudo_labeled_samples_ratio: 0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [00:31<01:39,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 71.33%\n",
            "Test accuracy: 69.15%\n",
            "\n",
            "Iteration 2 (cur_pseudo_labeled_samples_ratio: 0.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [00:55<02:15,  1.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 69.97%\n",
            "Test accuracy: 67.46%\n",
            "\n",
            "Iteration 3 (cur_pseudo_labeled_samples_ratio: 0.6000000000000001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 15/100 [00:37<03:30,  2.48s/it]\n",
            "[W 2024-05-26 22:37:36,369] Trial 13 failed with parameters: {} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_16048\\3422338356.py\", line 57, in objective\n",
            "    val_accuracy, model = train_with_curriculum_learning_and_get_max_accuracy_and_model(config)\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_16048\\3110056927.py\", line 34, in train_with_curriculum_learning_and_get_max_accuracy_and_model\n",
            "    val_accuracy = train_once_and_get_max_val_accuracy(config, labeled_train_data_loader, val_data_loader, checkpoint_file_path)\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_16048\\4091178723.py\", line 17, in train_once_and_get_max_val_accuracy\n",
            "    train_loss = train_single_epoch(\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_16048\\2746195472.py\", line 29, in train_single_epoch\n",
            "    outputs = model(inputs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py\", line 285, in forward\n",
            "    return self._forward_impl(x)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py\", line 274, in _forward_impl\n",
            "    x = self.layer2(x)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
            "    input = module(input)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py\", line 97, in forward\n",
            "    out = self.bn2(out)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\", line 175, in forward\n",
            "    return F.batch_norm(\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\functional.py\", line 2509, in batch_norm\n",
            "    return torch.batch_norm(\n",
            "KeyboardInterrupt\n",
            "[W 2024-05-26 22:37:36,369] Trial 13 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[36], line 57\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     50\u001b[0m third_last_layer_weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m third_last_layer_weight_decay_exp\n\u001b[0;32m     51\u001b[0m config\u001b[38;5;241m.\u001b[39mlast_layers_training_configs\u001b[38;5;241m.\u001b[39mappend(LastLayerTrainingConfig(\n\u001b[0;32m     52\u001b[0m     unfreeze_epoch\u001b[38;5;241m=\u001b[39mthird_last_layer_unfreeze_epoch,\n\u001b[0;32m     53\u001b[0m     lr\u001b[38;5;241m=\u001b[39mthird_last_layer_lr,\n\u001b[0;32m     54\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mthird_last_layer_weight_decay,\n\u001b[0;32m     55\u001b[0m     use_train_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     56\u001b[0m ))\n\u001b[1;32m---> 57\u001b[0m val_accuracy, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_curriculum_learning_and_get_max_accuracy_and_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_accuracy\n",
            "Cell \u001b[1;32mIn[35], line 34\u001b[0m, in \u001b[0;36mtrain_with_curriculum_learning_and_get_max_accuracy_and_model\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# train once and load best model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m checkpoint_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_once_and_get_max_val_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeled_train_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m model, _ \u001b[38;5;241m=\u001b[39m get_pretrained_model_and_model_trainable_layers(config\u001b[38;5;241m.\u001b[39mnum_classes, config\u001b[38;5;241m.\u001b[39mdevice)\n",
            "Cell \u001b[1;32mIn[20], line 17\u001b[0m, in \u001b[0;36mtrain_once_and_get_max_val_accuracy\u001b[1;34m(config, labeled_train_data_loader, val_data_loader, checkpoint_file_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# for epoch in range(config.max_num_epochs):\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mmax_num_epochs))):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# print(f'Epoch #{epoch}:')\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_single_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_trainable_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeled_train_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_layers_training_configs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# print(f'Train loss: {train_loss}')\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     val_accuracy \u001b[38;5;241m=\u001b[39m get_model_accuracy(model, val_data_loader)\n",
            "Cell \u001b[1;32mIn[13], line 29\u001b[0m, in \u001b[0;36mtrain_single_epoch\u001b[1;34m(model, model_trainable_layers, train_data_loader, criterion, optimizer, last_layers_training_configs, epoch)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_data_loader:\n\u001b[0;32m     28\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 29\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     31\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py:97\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[1;32m---> 97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\functional.py:2509\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2507\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FrozenTrial(number=12, state=TrialState.COMPLETE, values=[0.6494565367698669], datetime_start=datetime.datetime(2024, 5, 26, 16, 4, 12, 841406), datetime_complete=datetime.datetime(2024, 5, 26, 16, 6, 53, 389318), params={'batch_size_exp': 4, 'last_layer_lr_exp': -3.862332103325873, 'last_layer_weight_decay_exp': -2.520447729733064, 'second_last_layer_unfreeze_epoch': 6, 'second_last_layer_lr_exp': -3.7985851526938648, 'second_last_layer_weight_decay_exp': -2.218563662514852, 'third_last_layer_unfreeze_epoch': 6, 'third_last_layer_lr_exp': -3.636363070796339, 'third_last_layer_weight_decay_exp': -1.9693380362468311}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size_exp': IntDistribution(high=5, log=False, low=3, step=1), 'last_layer_lr_exp': FloatDistribution(high=-2.0, log=False, low=-4.0, step=None), 'last_layer_weight_decay_exp': FloatDistribution(high=-2.0, log=False, low=-4.0, step=None), 'second_last_layer_unfreeze_epoch': IntDistribution(high=10, log=False, low=1, step=1), 'second_last_layer_lr_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None), 'second_last_layer_weight_decay_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None), 'third_last_layer_unfreeze_epoch': IntDistribution(high=15, log=False, low=6, step=1), 'third_last_layer_lr_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None), 'third_last_layer_weight_decay_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None)}, trial_id=12, value=None)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
