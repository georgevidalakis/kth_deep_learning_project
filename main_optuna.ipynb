{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzA4wZLlOZJQ",
        "outputId": "d18ee9a2-19a5-4490-d8d6-bbc463deed36"
      },
      "outputs": [],
      "source": [
        "# !unzip drive/MyDrive/Pets-data/images.zip\n",
        "# !cp -r drive/MyDrive/Pets-data/annotations .\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "G05VSG-WExN-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "from typing import Tuple, List\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from pydantic import BaseModel\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mw2iUZkZXMW3"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "\n",
        "CONFIG_FILE_PATH = 'config_optuna.yaml'\n",
        "IMAGE_COL_IDX = 0\n",
        "CLASS_ID_COL_IDX = 1\n",
        "SPECIES_COL_IDX = 2\n",
        "POSSIBLE_NUM_CLASSES = {2, 37}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V_BHkWLlXMW3"
      },
      "outputs": [],
      "source": [
        "class AdamOptimizerConfig(BaseModel):\n",
        "    lr: float\n",
        "    weight_decay: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LastLayerTrainingConfig(BaseModel):\n",
        "    unfreeze_epoch: int\n",
        "    lr: float\n",
        "    weight_decay: float\n",
        "    use_train_mode: bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "XkhfRZxKXMW4"
      },
      "outputs": [],
      "source": [
        "class Config(BaseModel):\n",
        "    device: str\n",
        "    num_classes: int\n",
        "    batch_size: int\n",
        "    max_num_epochs: int\n",
        "    patience: int\n",
        "    # adam_optimizer_config: AdamOptimizerConfig\n",
        "    # num_batch_norm_layers_to_train_params: int\n",
        "    # num_batch_norm_layers_to_update_running_stats: int\n",
        "    # train_earlier_layers_delay: int\n",
        "    # n_hidden_layers_to_train: int\n",
        "    last_layers_training_configs: List[LastLayerTrainingConfig]\n",
        "    use_pseudo_labelling: int\n",
        "    labelled_data_ratio: float\n",
        "    T_1: int\n",
        "    T_2: int\n",
        "    ALPHA_F: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4nXmlOeyXMW4"
      },
      "outputs": [],
      "source": [
        "with open(CONFIG_FILE_PATH, encoding='utf-8') as f:\n",
        "    config_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
        "\n",
        "config = Config.model_validate(config_dict)\n",
        "\n",
        "assert config.num_classes in POSSIBLE_NUM_CLASSES\n",
        "# assert 0 <= config.num_batch_norm_layers_to_train_params <= 36  # 36 batch norm layers in resnet34\n",
        "# assert 0 <= config.num_batch_norm_layers_to_update_running_stats <= 36  # 36 batch norm layers in resnet34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3bs_rvb7HsqY"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, filenames: List[str], labels: List[int], use_augmentations: bool) -> None:\n",
        "        self.filenames = filenames\n",
        "        self.labels = labels\n",
        "        # self.transformation = torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        self.transformation = (\n",
        "            transforms.Compose([\n",
        "                transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
        "                # transforms.CenterCrop(size=224),\n",
        "                transforms.PILToTensor(),\n",
        "                transforms.ConvertImageDtype(dtype=torch.float),\n",
        "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "                # torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms(),\n",
        "                # transforms.RandomCrop((what size, what other size)),\n",
        "                transforms.CenterCrop(size=256),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                # transforms.RandomRotation(degrees=(-30, 30), expand=True),\n",
        "                transforms.RandomResizedCrop(size=224),\n",
        "                # transforms.RandomErasing(),\n",
        "            ])\n",
        "            if use_augmentations\n",
        "            else torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        )\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        image = Image.open(os.path.join('images', f'{self.filenames[idx]}.jpg')).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        transformed_img = self.transformation(image)\n",
        "\n",
        "        return transformed_img.to(config.device), torch.tensor(label).to(config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageDatasetPseudoLabels(Dataset):\n",
        "    def __init__(self, labelled_filenames: List[str], labels: List[int], unlabelled_filenames: List[str], use_augmentations: bool) -> None:\n",
        "        self.labelled_filenames = labelled_filenames\n",
        "        self.labels = labels\n",
        "        self.unlabelled_filenames = unlabelled_filenames\n",
        "\n",
        "        assert len(labelled_filenames) == len(labels), 'labels must have the same size as labelled_filenames'\n",
        "\n",
        "        # self.transformation = torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        self.transformation = (\n",
        "            transforms.Compose([\n",
        "                transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
        "                # transforms.CenterCrop(size=224),\n",
        "                transforms.PILToTensor(),\n",
        "                transforms.ConvertImageDtype(dtype=torch.float),\n",
        "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "                # torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms(),\n",
        "                # transforms.RandomCrop((what size, what other size)),\n",
        "                transforms.CenterCrop(size=256),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                # transforms.RandomRotation(degrees=(-30, 30), expand=True),\n",
        "                transforms.RandomResizedCrop(size=224),\n",
        "                # transforms.RandomErasing(),\n",
        "            ])\n",
        "            if use_augmentations\n",
        "            else torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        )\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labelled_filenames) + len(self.unlabelled_filenames)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        if idx >= len(self.labelled_filenames): # Returning an unlabelled image\n",
        "            image = Image.open(os.path.join('images', f'{self.unlabelled_filenames[idx - len(self.labelled_filenames)]}.jpg')).convert('RGB')\n",
        "            transformed_img = self.transformation(image)\n",
        "            return transformed_img.to(config.device), torch.tensor(-1).float().to(config.device)\n",
        "\n",
        "        image = Image.open(os.path.join('images', f'{self.labelled_filenames[idx]}.jpg')).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        transformed_img = self.transformation(image)\n",
        "\n",
        "        return transformed_img.to(config.device), torch.tensor(label).to(config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VWB1d993Kmmp"
      },
      "outputs": [],
      "source": [
        "def get_image_names_and_labels(annotations_file_path: str, num_classes: int) -> Tuple[List[str], List[int]]:\n",
        "    filenames: List[str] = []\n",
        "    labels: List[int] = []\n",
        "\n",
        "    with open(annotations_file_path, encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    label_col_idx = SPECIES_COL_IDX if num_classes == 2 else CLASS_ID_COL_IDX\n",
        "\n",
        "    for line in lines:\n",
        "        line_split = line.split()\n",
        "        filenames.append(line_split[IMAGE_COL_IDX])\n",
        "        labels.append(int(line_split[label_col_idx]) - 1)\n",
        "\n",
        "    return filenames, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SWMeQTkAXMW5"
      },
      "outputs": [],
      "source": [
        "# def get_batch_norm_layers(model: nn.Module) -> List[nn.Module]:\n",
        "#     return [\n",
        "#         module\n",
        "#         for module in model.modules()\n",
        "#         if isinstance(module, nn.BatchNorm2d)\n",
        "#     ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nopF1mMoExN_"
      },
      "outputs": [],
      "source": [
        "# def get_pretrained_model_with_trainable_last_layer(num_batch_norm_layers_to_train_params: int) -> nn.Module:\n",
        "#     model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "#     for param in model.parameters():\n",
        "#         param.requires_grad = False\n",
        "\n",
        "#     batch_norm_layers = get_batch_norm_layers(model)\n",
        "#     batch_norm_layers_to_train_params = batch_norm_layers[-num_batch_norm_layers_to_train_params:] if num_batch_norm_layers_to_train_params else []\n",
        "\n",
        "#     for batch_norm_layer in batch_norm_layers_to_train_params:\n",
        "#         for param in batch_norm_layer.parameters():\n",
        "#             param.requires_grad = True\n",
        "\n",
        "#     model.fc = nn.Linear(in_features=model.fc.in_features, out_features=config.num_classes)\n",
        "\n",
        "#     return model.to(config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FBNnljpQZdTp"
      },
      "outputs": [],
      "source": [
        "# def get_pretrained_model_with_trainable_n_layers(num_batch_norm_layers_to_train_params: int, number_of_hidden_layers_to_train: int=0) -> nn.Module:\n",
        "#     model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "#     for param in model.parameters():\n",
        "#         param.requires_grad = False\n",
        "\n",
        "#     batch_norm_layers = get_batch_norm_layers(model)\n",
        "#     batch_norm_layers_to_train_params = batch_norm_layers[-num_batch_norm_layers_to_train_params:] if num_batch_norm_layers_to_train_params else []\n",
        "\n",
        "#     for batch_norm_layer in batch_norm_layers_to_train_params:\n",
        "#         for param in batch_norm_layer.parameters():\n",
        "#             param.requires_grad = True\n",
        "\n",
        "#     model.fc = nn.Linear(in_features=model.fc.in_features, out_features=config.num_classes)\n",
        "\n",
        "#     trainable_layers = [layer for layer in model.modules() if not isinstance(layer, torchvision.models.resnet.ResNet) and not isinstance(layer, torchvision.models.resnet.BasicBlock) and not isinstance(layer, nn.Sequential) and not isinstance(layer, nn.Sequential) and len(list(layer.parameters())) > 0]\n",
        "#     trainable_layers = list(reversed(trainable_layers[:-1]))\n",
        "\n",
        "#     for l in trainable_layers[:number_of_hidden_layers_to_train]:\n",
        "#         for p in l.parameters():\n",
        "#             p.requires_grad = True\n",
        "\n",
        "#     return model.to(config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_pretrained_model_and_model_trainable_layers() -> nn.Module:\n",
        "    model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=config.num_classes)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model_trainable_layers = [\n",
        "        layer\n",
        "        for layer in model.modules()\n",
        "        if (not isinstance(layer, torchvision.models.resnet.ResNet) and\n",
        "            not isinstance(layer, torchvision.models.resnet.BasicBlock) and\n",
        "            not isinstance(layer, nn.Sequential) and not isinstance(layer, nn.Sequential) and\n",
        "            len(list(layer.parameters())) > 0)\n",
        "    ]\n",
        "\n",
        "    return model.to(config.device), model_trainable_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Xx6TYx-30Gy7"
      },
      "outputs": [],
      "source": [
        "# def make_hidden_layers_trainable(model: nn.Module, number_of_hidden_layers_to_train: int) -> nn.Module:\n",
        "#     trainable_layers = [layer for layer in model.modules() if not isinstance(layer, torchvision.models.resnet.ResNet) and not isinstance(layer, torchvision.models.resnet.BasicBlock) and not isinstance(layer, nn.Sequential) and not isinstance(layer, nn.Sequential) and len(list(layer.parameters())) > 0]\n",
        "#     trainable_layers = list(reversed(trainable_layers[:-1]))\n",
        "\n",
        "#     for l in trainable_layers[:number_of_hidden_layers_to_train]:\n",
        "#         for p in l.parameters():\n",
        "#             p.requires_grad = True\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PPeg-qfgXMW6"
      },
      "outputs": [],
      "source": [
        "def get_model_accuracy(model: nn.Module, data_loader: DataLoader) -> float:\n",
        "    correct_predictions_cnt = 0\n",
        "    total_predictions_cnt = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # for inputs, labels in tqdm(data_loader, desc='Computing accuracy'):\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            correct_predictions_cnt += (torch.argmax(outputs, axis=1) == labels).sum()\n",
        "            total_predictions_cnt += len(outputs)\n",
        "    return correct_predictions_cnt / total_predictions_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ij6jIhTVXMW6"
      },
      "outputs": [],
      "source": [
        "# def train_single_epoch_old(\n",
        "#         model: nn.Module,\n",
        "#         train_data_loader: DataLoader,\n",
        "#         criterion: nn.Module,\n",
        "#         optimizer: torch.optim.Optimizer,\n",
        "#         num_batch_norm_layers_to_update_running_stats: int,\n",
        "#         ) -> float:\n",
        "#     model.train()\n",
        "#     batch_norm_layers = get_batch_norm_layers(model)\n",
        "#     batch_norm_layers_to_not_update_running_stats = (\n",
        "#         batch_norm_layers[:-num_batch_norm_layers_to_update_running_stats]\n",
        "#         if num_batch_norm_layers_to_update_running_stats\n",
        "#         else batch_norm_layers\n",
        "#     )\n",
        "#     for batch_norm_layer in batch_norm_layers_to_not_update_running_stats:\n",
        "#         batch_norm_layer.eval()\n",
        "#     train_loss_sum = 0.0\n",
        "#     train_samples_cnt = 0\n",
        "#     for inputs, labels in tqdm(train_data_loader, desc='Training model'):\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         train_loss_sum += loss.item() * len(outputs)\n",
        "#         train_samples_cnt += len(outputs)\n",
        "#     return train_loss_sum / train_samples_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_single_epoch(\n",
        "        model: nn.Module,\n",
        "        model_trainable_layers: List[nn.Module],\n",
        "        train_data_loader: DataLoader,\n",
        "        criterion: nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        last_layers_training_configs: List[LastLayerTrainingConfig],\n",
        "        epoch: int,\n",
        "        ) -> float:\n",
        "    model.eval()\n",
        "    for layer_reverse_idx, layer_training_config in enumerate(last_layers_training_configs):\n",
        "        layer = model_trainable_layers[-layer_reverse_idx - 1]\n",
        "        if layer_training_config.unfreeze_epoch <= epoch:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True\n",
        "            if layer_training_config.use_train_mode:\n",
        "                layer.train()\n",
        "        if layer_reverse_idx and layer_training_config.unfreeze_epoch == epoch:\n",
        "            optimizer.add_param_group({\n",
        "                'params': layer.parameters(),\n",
        "                'lr': layer_training_config.lr,\n",
        "                'weight_decay': layer_training_config.weight_decay,\n",
        "            })\n",
        "    train_loss_sum = 0.0\n",
        "    train_samples_cnt = 0\n",
        "    # for inputs, labels in tqdm(train_data_loader, desc='Training model'):\n",
        "    for inputs, labels in train_data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_sum += loss.item() * len(outputs)\n",
        "        train_samples_cnt += len(outputs)\n",
        "    return train_loss_sum / train_samples_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def alpha(t):\n",
        "    if t < config.T_1:\n",
        "        return 0\n",
        "    elif config.T_1 <= t and t < config.T_2:\n",
        "        return ((t - config.T_1) / (config.T_2-config.T_1)) * config.ALPHA_F\n",
        "    return config.ALPHA_F\n",
        "\n",
        "\n",
        "def train_single_epoch_pseudo(\n",
        "        model: nn.Module,\n",
        "        model_trainable_layers: List[nn.Module],\n",
        "        train_data_loader: DataLoader,\n",
        "        criterion: nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        last_layers_training_configs: List[LastLayerTrainingConfig],\n",
        "        epoch: int,\n",
        "        ) -> float:\n",
        "    model.eval()\n",
        "    for layer_reverse_idx, layer_training_config in enumerate(last_layers_training_configs):\n",
        "        layer = model_trainable_layers[-layer_reverse_idx - 1]\n",
        "        if layer_training_config.unfreeze_epoch <= epoch:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True\n",
        "            if layer_training_config.use_train_mode:\n",
        "                layer.train()\n",
        "        if layer_reverse_idx and layer_training_config.unfreeze_epoch == epoch:\n",
        "            optimizer.add_param_group({\n",
        "                'params': layer.parameters(),\n",
        "                'lr': layer_training_config.lr,\n",
        "                'weight_decay': layer_training_config.weight_decay,\n",
        "            })\n",
        "    train_loss_sum = 0.0\n",
        "    train_samples_cnt = 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_data_loader, desc='Training model'):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        labelled_idxs = torch.tensor([x[0] for x in enumerate(labels) if not x[1] == -1]).long().to(config.device)\n",
        "        unlabelled_idxs = torch.tensor([x[0] for x in enumerate(labels) if x[1] == -1]).long().to(config.device)\n",
        "\n",
        "        labelled_labels = torch.index_select(labels, 0, labelled_idxs).long()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        labelled_outputs = torch.index_select(outputs, 0, labelled_idxs)\n",
        "        unlabelled_outputs = torch.index_select(outputs, 0, unlabelled_idxs)\n",
        "\n",
        "        unlabelled_labels = torch.argmax(unlabelled_outputs, axis=1)\n",
        "\n",
        "        labelled_loss = criterion(labelled_outputs, labelled_labels)\n",
        "        unlabelled_loss = criterion(unlabelled_outputs, unlabelled_labels)\n",
        "        loss = 0\n",
        "\n",
        "        if not np.isnan(labelled_loss.item()):\n",
        "            loss = loss + labelled_loss\n",
        "        if not np.isnan(unlabelled_loss.item()):\n",
        "            loss = loss + alpha(epoch) * unlabelled_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_sum += loss.item() * len(outputs)\n",
        "        train_samples_cnt += len(outputs)\n",
        "\n",
        "    return train_loss_sum / train_samples_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XIdYAijVXMW7"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model: nn.Module, optimizer: torch.optim.Optimizer) -> Tuple[nn.Module, torch.optim.Optimizer]:\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, 'checkpoint.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "puyQaj1KXMW7"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(model: nn.Module, optimizer: torch.optim.Optimizer) -> None:\n",
        "    checkpoint = torch.load('checkpoint.pt')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "l_Z-eIVoExOB"
      },
      "outputs": [],
      "source": [
        "filenames_trainval, labels_trainval = get_image_names_and_labels('annotations/trainval.txt', num_classes=config.num_classes)\n",
        "filenames_test, labels_test = get_image_names_and_labels('annotations/test.txt', num_classes=config.num_classes)\n",
        "filenames_train, filenames_val, labels_train, labels_val = train_test_split(filenames_trainval, labels_trainval, test_size=0.2, stratify=labels_trainval)\n",
        "\n",
        "\n",
        "if config.use_pseudo_labelling:\n",
        "    filenames_train, unlabelled_filenames_train, labels_train, _ = train_test_split(filenames_train, labels_train, train_size=config.labelled_data_ratio, stratify=labels_train)\n",
        "    dataset_train = ImageDatasetPseudoLabels(filenames_train, labels_train, unlabelled_filenames_train, use_augmentations=True)\n",
        "    labelled_dataset_train = ImageDataset(filenames_train, labels_train, use_augmentations=True)\n",
        "    labelled_train_data_loader = DataLoader(labelled_dataset_train, batch_size=config.batch_size, shuffle=True)\n",
        "else:\n",
        "    dataset_train = ImageDataset(filenames_train, labels_train, use_augmentations=True)\n",
        "\n",
        "\n",
        "dataset_train = ImageDataset(filenames_train, labels_train, use_augmentations=True)\n",
        "dataset_val = ImageDataset(filenames_val, labels_val, use_augmentations=False)\n",
        "dataset_test = ImageDataset(filenames_test, labels_test, use_augmentations=False)\n",
        "\n",
        "train_data_loader = DataLoader(dataset_train, batch_size=config.batch_size, shuffle=True)\n",
        "val_data_loader = DataLoader(dataset_val, batch_size=config.batch_size, shuffle=False)\n",
        "test_data_loader = DataLoader(dataset_test, batch_size=config.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_get_max_val_accuracy(config: Config) -> float:\n",
        "    model, model_trainable_layers = get_pretrained_model_and_model_trainable_layers()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model_trainable_layers[-1].parameters(),\n",
        "        lr=config.last_layers_training_configs[0].lr,\n",
        "        weight_decay=config.last_layers_training_configs[0].weight_decay,\n",
        "    )\n",
        "\n",
        "    max_val_accuracy = float('-inf')\n",
        "    argmax_epoch = -1\n",
        "\n",
        "    for epoch in range(config.max_num_epochs):\n",
        "        # print(f'Epoch #{epoch}:')\n",
        "        train_loss = train_single_epoch_pseudo(\n",
        "            model, model_trainable_layers, train_data_loader, criterion, optimizer, config.last_layers_training_configs, epoch\n",
        "        )\n",
        "        print(f'Train loss: {train_loss}')\n",
        "        val_accuracy = get_model_accuracy(model, val_data_loader)\n",
        "        if val_accuracy > max_val_accuracy:\n",
        "            print(f'Validation accuracy: {100 * val_accuracy:.2f}% (new best)')\n",
        "            max_val_accuracy = val_accuracy\n",
        "            argmax_epoch = epoch\n",
        "            # save_checkpoint(model, optimizer)\n",
        "            # print('Checkpoint saved')\n",
        "        else:\n",
        "            print(f'Validation accuracy: {100 * val_accuracy:.2f}% (worse than {100 * max_val_accuracy:.2f}% of epoch {argmax_epoch})')\n",
        "            if epoch > argmax_epoch + config.patience:\n",
        "                print(f'Early stopping')\n",
        "                break\n",
        "        # # Start training earlier layers\n",
        "        # if epoch == config.train_earlier_layers_delay and config.n_hidden_layers_to_train > 0:\n",
        "        #     print (f'Making last {config.n_hidden_layers_to_train} hidden layers trainable')\n",
        "        #     make_hidden_layers_trainable(model, config.n_hidden_layers_to_train)\n",
        "        #     optimizer = torch.optim.Adam(model.parameters(), lr=config.adam_optimizer_config.lr / 100, weight_decay=config.adam_optimizer_config.weight_decay)\n",
        "        # print()\n",
        "    return max_val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYVA1JYkN0ZB",
        "outputId": "d0ab9637-378d-402f-d24e-a94f19ff11c1"
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial):\n",
        "    batch_size_exp = trial.suggest_int(\"batch_size_exp\", 3, 7)\n",
        "    batch_size = 2 ** batch_size_exp\n",
        "    config = Config(\n",
        "        device='cuda:0',\n",
        "        num_classes=37,\n",
        "        batch_size=batch_size,\n",
        "        max_num_epochs=40,\n",
        "        patience=10,\n",
        "        last_layers_training_configs=[],\n",
        "        # pseudo-labeling\n",
        "        use_pseudo_labelling=1,\n",
        "        labelled_data_ratio=0.1,\n",
        "        T_1=1_000,\n",
        "        T_2=1_000,\n",
        "        ALPHA_F=3,\n",
        "    )\n",
        "    last_layer_lr_exp = trial.suggest_float(\"last_layer_lr_exp\", -4.0, -2.0)\n",
        "    last_layer_weight_decay_exp = trial.suggest_float(\"last_layer_weight_decay_exp\", -4.0, -2.0)\n",
        "    last_layer_lr = 10.0 ** last_layer_lr_exp\n",
        "    last_layer_weight_decay = 10.0 ** last_layer_weight_decay_exp\n",
        "    config.last_layers_training_configs.append(LastLayerTrainingConfig(\n",
        "        unfreeze_epoch=0,\n",
        "        lr=last_layer_lr,\n",
        "        weight_decay=last_layer_weight_decay,\n",
        "        use_train_mode=True,\n",
        "    ))\n",
        "    second_last_layer_unfreeze_epoch = trial.suggest_int(\"second_last_layer_unfreeze_epoch\", 1, 10)\n",
        "    second_last_layer_lr_exp = trial.suggest_float(\"second_last_layer_lr_exp\", -5.0, -1.0)\n",
        "    second_last_layer_weight_decay_exp = trial.suggest_float(\"second_last_layer_weight_decay_exp\", -5.0, -1.0)\n",
        "    second_last_layer_lr = 10.0 ** second_last_layer_lr_exp\n",
        "    second_last_layer_weight_decay = 10.0 ** second_last_layer_weight_decay_exp\n",
        "    config.last_layers_training_configs.append(LastLayerTrainingConfig(\n",
        "        unfreeze_epoch=second_last_layer_unfreeze_epoch,\n",
        "        lr=second_last_layer_lr,\n",
        "        weight_decay=second_last_layer_weight_decay,\n",
        "        use_train_mode=True,\n",
        "    ))\n",
        "    third_last_layer_unfreeze_epoch = trial.suggest_int(\"third_last_layer_unfreeze_epoch\", second_last_layer_unfreeze_epoch, 15)\n",
        "    third_last_layer_lr_exp = trial.suggest_float(\"third_last_layer_lr_exp\", -5.0, -1.0)\n",
        "    third_last_layer_weight_decay_exp = trial.suggest_float(\"third_last_layer_weight_decay_exp\", -5.0, -1.0)\n",
        "    third_last_layer_lr = 10.0 ** third_last_layer_lr_exp\n",
        "    third_last_layer_weight_decay = 10.0 ** third_last_layer_weight_decay_exp\n",
        "    config.last_layers_training_configs.append(LastLayerTrainingConfig(\n",
        "        unfreeze_epoch=third_last_layer_unfreeze_epoch,\n",
        "        lr=third_last_layer_lr,\n",
        "        weight_decay=third_last_layer_weight_decay,\n",
        "        use_train_mode=True,\n",
        "    ))\n",
        "    return train_and_get_max_val_accuracy(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-22 09:07:14,629] A new study created in memory with name: no-name-b3c4aa57-aa7e-428f-b0f1-3429b80fb546\n",
            "Training model: 100%|██████████| 10/10 [00:01<00:00,  5.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 3.5890536356945426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2024-05-22 09:07:18,863] Trial 0 failed with parameters: {'batch_size_exp': 5, 'last_layer_lr_exp': -2.2777062255790144, 'last_layer_weight_decay_exp': -2.9649743716673593, 'second_last_layer_unfreeze_epoch': 4, 'second_last_layer_lr_exp': -1.605894325812685, 'second_last_layer_weight_decay_exp': -2.2251746661797274, 'third_last_layer_unfreeze_epoch': 12, 'third_last_layer_lr_exp': -1.2197903756926198, 'third_last_layer_weight_decay_exp': -1.473720350516397} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_7672\\3602300019.py\", line 50, in objective\n",
            "    return train_and_get_max_val_accuracy(config)\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_7672\\3791173904.py\", line 20, in train_and_get_max_val_accuracy\n",
            "    val_accuracy = get_model_accuracy(model, val_data_loader)\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_7672\\3879608583.py\", line 8, in get_model_accuracy\n",
            "    outputs = model(inputs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py\", line 285, in forward\n",
            "    return self._forward_impl(x)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py\", line 274, in _forward_impl\n",
            "    x = self.layer2(x)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
            "    input = module(input)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py\", line 93, in forward\n",
            "    out = self.bn1(out)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\", line 175, in forward\n",
            "    return F.batch_norm(\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\functional.py\", line 2509, in batch_norm\n",
            "    return torch.batch_norm(\n",
            "KeyboardInterrupt\n",
            "[W 2024-05-22 09:07:18,865] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[43], line 50\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     43\u001b[0m third_last_layer_weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m third_last_layer_weight_decay_exp\n\u001b[0;32m     44\u001b[0m config\u001b[38;5;241m.\u001b[39mlast_layers_training_configs\u001b[38;5;241m.\u001b[39mappend(LastLayerTrainingConfig(\n\u001b[0;32m     45\u001b[0m     unfreeze_epoch\u001b[38;5;241m=\u001b[39mthird_last_layer_unfreeze_epoch,\n\u001b[0;32m     46\u001b[0m     lr\u001b[38;5;241m=\u001b[39mthird_last_layer_lr,\n\u001b[0;32m     47\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mthird_last_layer_weight_decay,\n\u001b[0;32m     48\u001b[0m     use_train_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m ))\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_and_get_max_val_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[38], line 20\u001b[0m, in \u001b[0;36mtrain_and_get_max_val_accuracy\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     16\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_single_epoch_pseudo(\n\u001b[0;32m     17\u001b[0m     model, model_trainable_layers, train_data_loader, criterion, optimizer, config\u001b[38;5;241m.\u001b[39mlast_layers_training_configs, epoch\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_accuracy \u001b[38;5;241m>\u001b[39m max_val_accuracy:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% (new best)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[19], line 8\u001b[0m, in \u001b[0;36mget_model_accuracy\u001b[1;34m(model, data_loader)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# for inputs, labels in tqdm(data_loader, desc='Computing accuracy'):\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m----> 8\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m         correct_predictions_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39margmax(outputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     10\u001b[0m         total_predictions_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(outputs)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torchvision\\models\\resnet.py:93\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     90\u001b[0m identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     92\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m---> 93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\torch\\nn\\functional.py:2509\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2507\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FrozenTrial(number=11, state=TrialState.COMPLETE, values=[0.9510869979858398], datetime_start=datetime.datetime(2024, 5, 21, 21, 52, 13, 728210), datetime_complete=datetime.datetime(2024, 5, 21, 22, 1, 12, 874608), params={'batch_size_exp': 5, 'last_layer_lr_exp': -2.8552450749872538, 'last_layer_weight_decay_exp': -3.262432218991849, 'second_last_layer_unfreeze_epoch': 1, 'second_last_layer_lr_exp': -2.635150903871032, 'second_last_layer_weight_decay_exp': -2.394793163781819, 'third_last_layer_unfreeze_epoch': 4, 'third_last_layer_lr_exp': -4.8965012088919515, 'third_last_layer_weight_decay_exp': -3.543387070729529}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size_exp': IntDistribution(high=7, log=False, low=3, step=1), 'last_layer_lr_exp': FloatDistribution(high=-2.0, log=False, low=-4.0, step=None), 'last_layer_weight_decay_exp': FloatDistribution(high=-2.0, log=False, low=-4.0, step=None), 'second_last_layer_unfreeze_epoch': IntDistribution(high=10, log=False, low=1, step=1), 'second_last_layer_lr_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None), 'second_last_layer_weight_decay_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None), 'third_last_layer_unfreeze_epoch': IntDistribution(high=15, log=False, low=1, step=1), 'third_last_layer_lr_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None), 'third_last_layer_weight_decay_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None)}, trial_id=11, value=None)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR85iuaLXMW9",
        "outputId": "0f984362-01e7-47f8-cdb4-310d5ef63e17"
      },
      "outputs": [],
      "source": [
        "load_checkpoint(model, optimizer)\n",
        "print('Checkpoint loaded')\n",
        "\n",
        "test_accuracy = get_model_accuracy(model, test_data_loader)\n",
        "\n",
        "print(f'Test accuracy: {100 * test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
