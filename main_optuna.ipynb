{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzA4wZLlOZJQ",
        "outputId": "d18ee9a2-19a5-4490-d8d6-bbc463deed36"
      },
      "outputs": [],
      "source": [
        "# !unzip drive/MyDrive/Pets-data/images.zip\n",
        "# !cp -r drive/MyDrive/Pets-data/annotations .\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G05VSG-WExN-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yaml\n",
        "from typing import Tuple, List, Optional\n",
        "\n",
        "import torch\n",
        "import optuna\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from pydantic import BaseModel\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mw2iUZkZXMW3"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "\n",
        "CONFIG_FILE_PATH = 'config_optuna.yaml'\n",
        "IMAGE_COL_IDX = 0\n",
        "CLASS_ID_COL_IDX = 1\n",
        "SPECIES_COL_IDX = 2\n",
        "POSSIBLE_NUM_CLASSES = {2, 37}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V_BHkWLlXMW3"
      },
      "outputs": [],
      "source": [
        "class AdamOptimizerConfig(BaseModel):\n",
        "    lr: float\n",
        "    weight_decay: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LastLayerTrainingConfig(BaseModel):\n",
        "    unfreeze_epoch: int\n",
        "    lr: float\n",
        "    weight_decay: float\n",
        "    use_train_mode: bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XkhfRZxKXMW4"
      },
      "outputs": [],
      "source": [
        "class Config(BaseModel):\n",
        "    device: str\n",
        "    num_classes: int\n",
        "    batch_size: int\n",
        "    max_num_epochs: int\n",
        "    patience: int\n",
        "    # adam_optimizer_config: AdamOptimizerConfig\n",
        "    # num_batch_norm_layers_to_train_params: int\n",
        "    # num_batch_norm_layers_to_update_running_stats: int\n",
        "    # train_earlier_layers_delay: int\n",
        "    # n_hidden_layers_to_train: int\n",
        "    last_layers_training_configs: List[LastLayerTrainingConfig]\n",
        "    use_pseudo_labelling: int\n",
        "    labelled_data_ratio: float\n",
        "    T_1: int\n",
        "    T_2: int\n",
        "    ALPHA_F: float\n",
        "    unlabelled_batch_size: int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4nXmlOeyXMW4"
      },
      "outputs": [],
      "source": [
        "# with open(CONFIG_FILE_PATH, encoding='utf-8') as f:\n",
        "#     config_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
        "\n",
        "# config_test = Config.model_validate(config_dict)\n",
        "\n",
        "# assert config_test.num_classes in POSSIBLE_NUM_CLASSES\n",
        "# # assert 0 <= config.num_batch_norm_layers_to_train_params <= 36  # 36 batch norm layers in resnet34\n",
        "# # assert 0 <= config.num_batch_norm_layers_to_update_running_stats <= 36  # 36 batch norm layers in resnet34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3bs_rvb7HsqY"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, filenames: List[str], labels: List[int], use_augmentations: bool, device: str) -> None:\n",
        "        self.filenames = filenames\n",
        "        self.labels = labels\n",
        "        # self.transformation = torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        self.transformation = (\n",
        "            transforms.Compose([\n",
        "                transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
        "                # transforms.CenterCrop(size=224),\n",
        "                transforms.PILToTensor(),\n",
        "                transforms.ConvertImageDtype(dtype=torch.float),\n",
        "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "                # torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms(),\n",
        "                # transforms.RandomCrop((what size, what other size)),\n",
        "                transforms.CenterCrop(size=256),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                # transforms.RandomRotation(degrees=(-30, 30), expand=True),\n",
        "                transforms.RandomResizedCrop(size=224),\n",
        "                # transforms.RandomErasing(),\n",
        "            ])\n",
        "            if use_augmentations\n",
        "            else torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        )\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        image = Image.open(os.path.join('images', f'{self.filenames[idx]}.jpg')).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        transformed_img = self.transformation(image)\n",
        "\n",
        "        return transformed_img.to(self.device), torch.tensor(label).to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageDatasetPseudoLabels(Dataset):\n",
        "    def __init__(self, labelled_filenames: List[str], labels: List[int], unlabelled_filenames: List[str], use_augmentations: bool, device: str) -> None:\n",
        "        self.labelled_filenames = labelled_filenames\n",
        "        self.labels = labels\n",
        "        self.unlabelled_filenames = unlabelled_filenames\n",
        "\n",
        "        assert len(labelled_filenames) == len(labels), 'labels must have the same size as labelled_filenames'\n",
        "\n",
        "        # self.transformation = torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        self.transformation = (\n",
        "            transforms.Compose([\n",
        "                transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
        "                # transforms.CenterCrop(size=224),\n",
        "                transforms.PILToTensor(),\n",
        "                transforms.ConvertImageDtype(dtype=torch.float),\n",
        "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "                # torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms(),\n",
        "                # transforms.RandomCrop((what size, what other size)),\n",
        "                transforms.CenterCrop(size=256),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                # transforms.RandomRotation(degrees=(-30, 30), expand=True),\n",
        "                transforms.RandomResizedCrop(size=224),\n",
        "                # transforms.RandomErasing(),\n",
        "            ])\n",
        "            if use_augmentations\n",
        "            else torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        )\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labelled_filenames) + len(self.unlabelled_filenames)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        if idx >= len(self.labelled_filenames): # Returning an unlabelled image\n",
        "            image = Image.open(os.path.join('images', f'{self.unlabelled_filenames[idx - len(self.labelled_filenames)]}.jpg')).convert('RGB')\n",
        "            transformed_img = self.transformation(image)\n",
        "            return transformed_img.to(self.device), torch.tensor(-1).float().to(self.device)\n",
        "\n",
        "        image = Image.open(os.path.join('images', f'{self.labelled_filenames[idx]}.jpg')).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        transformed_img = self.transformation(image)\n",
        "\n",
        "        return transformed_img.to(self.device), torch.tensor(label).to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnlabelledImageDataset(Dataset):\n",
        "    def __init__(self, filenames: List[str], use_augmentations: bool, device: str) -> None:\n",
        "        self.filenames = filenames\n",
        "        # self.transformation = torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        self.transformation = (\n",
        "            transforms.Compose([\n",
        "                transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
        "                # transforms.CenterCrop(size=224),\n",
        "                transforms.PILToTensor(),\n",
        "                transforms.ConvertImageDtype(dtype=torch.float),\n",
        "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "                # torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms(),\n",
        "                # transforms.RandomCrop((what size, what other size)),\n",
        "                transforms.CenterCrop(size=256),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                # transforms.RandomRotation(degrees=(-30, 30), expand=True),\n",
        "                transforms.RandomResizedCrop(size=224),\n",
        "                # transforms.RandomErasing(),\n",
        "            ])\n",
        "            if use_augmentations\n",
        "            else torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms()\n",
        "        )\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        image = Image.open(os.path.join('images', f'{self.filenames[idx]}.jpg')).convert('RGB')\n",
        "\n",
        "        transformed_img = self.transformation(image)\n",
        "\n",
        "        return transformed_img.to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VWB1d993Kmmp"
      },
      "outputs": [],
      "source": [
        "def get_image_names_and_labels(annotations_file_path: str, num_classes: int) -> Tuple[List[str], List[int]]:\n",
        "    filenames: List[str] = []\n",
        "    labels: List[int] = []\n",
        "\n",
        "    with open(annotations_file_path, encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    label_col_idx = SPECIES_COL_IDX if num_classes == 2 else CLASS_ID_COL_IDX\n",
        "\n",
        "    for line in lines:\n",
        "        line_split = line.split()\n",
        "        filenames.append(line_split[IMAGE_COL_IDX])\n",
        "        labels.append(int(line_split[label_col_idx]) - 1)\n",
        "\n",
        "    return filenames, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_pretrained_model_and_model_trainable_layers(num_classes: int, device: str) -> nn.Module:\n",
        "    model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model_trainable_layers = [\n",
        "        layer\n",
        "        for layer in model.modules()\n",
        "        if (not isinstance(layer, torchvision.models.resnet.ResNet) and\n",
        "            not isinstance(layer, torchvision.models.resnet.BasicBlock) and\n",
        "            not isinstance(layer, nn.Sequential) and not isinstance(layer, nn.Sequential) and\n",
        "            len(list(layer.parameters())) > 0)\n",
        "    ]\n",
        "\n",
        "    return model.to(device), model_trainable_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PPeg-qfgXMW6"
      },
      "outputs": [],
      "source": [
        "def get_model_accuracy(model: nn.Module, data_loader: DataLoader) -> float:\n",
        "    correct_predictions_cnt = 0\n",
        "    total_predictions_cnt = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # for inputs, labels in tqdm(data_loader, desc='Computing accuracy'):\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            correct_predictions_cnt += (torch.argmax(outputs, axis=1) == labels).sum()\n",
        "            total_predictions_cnt += len(outputs)\n",
        "    return correct_predictions_cnt / total_predictions_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_single_epoch(\n",
        "        model: nn.Module,\n",
        "        model_trainable_layers: List[nn.Module],\n",
        "        train_data_loader: DataLoader,\n",
        "        criterion: nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        last_layers_training_configs: List[LastLayerTrainingConfig],\n",
        "        epoch: int,\n",
        "        ) -> float:\n",
        "    model.eval()\n",
        "    for layer_reverse_idx, layer_training_config in enumerate(last_layers_training_configs):\n",
        "        layer = model_trainable_layers[-layer_reverse_idx - 1]\n",
        "        if layer_training_config.unfreeze_epoch <= epoch:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True\n",
        "            if layer_training_config.use_train_mode:\n",
        "                layer.train()\n",
        "        if layer_reverse_idx and layer_training_config.unfreeze_epoch == epoch:\n",
        "            optimizer.add_param_group({\n",
        "                'params': layer.parameters(),\n",
        "                'lr': layer_training_config.lr,\n",
        "                'weight_decay': layer_training_config.weight_decay,\n",
        "            })\n",
        "    train_loss_sum = 0.0\n",
        "    train_samples_cnt = 0\n",
        "    # for inputs, labels in tqdm(train_data_loader, desc='Training model'):\n",
        "    for inputs, labels in train_data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_sum += loss.item() * len(outputs)\n",
        "        train_samples_cnt += len(outputs)\n",
        "    return train_loss_sum / train_samples_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def infinite_batch_generator(loader: DataLoader):\n",
        "    while True:\n",
        "        for batch in loader:\n",
        "            yield batch\n",
        "\n",
        "\n",
        "def get_alpha(t: int, T_1: int, T_2: int, ALPHA_F: float) -> float:\n",
        "    if t < T_1:\n",
        "        raise RuntimeError\n",
        "        # return 0.0\n",
        "    elif T_1 <= t and t < T_2:\n",
        "        return ((t - T_1) / (T_2 - T_1)) * ALPHA_F\n",
        "    return ALPHA_F\n",
        "\n",
        "\n",
        "def train_single_epoch_pseudo(\n",
        "        model: nn.Module,\n",
        "        model_trainable_layers: List[nn.Module],\n",
        "        train_data_loader: DataLoader,\n",
        "        unlabelled_train_data_loader: DataLoader,\n",
        "        criterion: nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        last_layers_training_configs: List[LastLayerTrainingConfig],\n",
        "        epoch: int,\n",
        "        T_1: int,\n",
        "        T_2: int,\n",
        "        ALPHA_F: float,\n",
        "        ) -> float:\n",
        "    model.eval()\n",
        "    for layer_reverse_idx, layer_training_config in enumerate(last_layers_training_configs):\n",
        "        layer = model_trainable_layers[-layer_reverse_idx - 1]\n",
        "        if layer_training_config.unfreeze_epoch <= epoch:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True\n",
        "            if layer_training_config.use_train_mode:\n",
        "                layer.train()\n",
        "        if layer_reverse_idx and layer_training_config.unfreeze_epoch == epoch:\n",
        "            optimizer.add_param_group({\n",
        "                'params': layer.parameters(),\n",
        "                'lr': layer_training_config.lr,\n",
        "                'weight_decay': layer_training_config.weight_decay,\n",
        "            })\n",
        "    train_loss_sum = 0.0\n",
        "    train_samples_cnt = 0\n",
        "\n",
        "    unlabelled_generator = infinite_batch_generator(unlabelled_train_data_loader)\n",
        "\n",
        "    # for labelled_inputs, labelled_labels in tqdm(train_data_loader, desc='Training model'):\n",
        "    for labelled_inputs, labelled_labels in train_data_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = 0.0\n",
        "\n",
        "        labelled_outputs = model(labelled_inputs)\n",
        "        labelled_loss = criterion(labelled_outputs, labelled_labels)\n",
        "        if not np.isnan(labelled_loss.item()):\n",
        "            loss += labelled_loss\n",
        "\n",
        "        if epoch >= T_1:\n",
        "            unlabelled_inputs = next(unlabelled_generator)\n",
        "            unlabelled_outputs = model(unlabelled_inputs)\n",
        "            unlabelled_labels = torch.argmax(unlabelled_outputs, axis=1)\n",
        "            unlabelled_loss = criterion(unlabelled_outputs, unlabelled_labels)\n",
        "            if not np.isnan(unlabelled_loss.item()):\n",
        "                loss += get_alpha(epoch, T_1, T_2, ALPHA_F) * unlabelled_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # train_loss_sum += loss.item() * (len(unlabelled_outputs) + len(labelled_outputs))\n",
        "        # train_samples_cnt += len(unlabelled_outputs) + len(labelled_outputs)\n",
        "        train_loss_sum += loss.item() * len(labelled_outputs)\n",
        "        train_samples_cnt += len(labelled_outputs)\n",
        "\n",
        "    return train_loss_sum / train_samples_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XIdYAijVXMW7"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model: nn.Module, optimizer: torch.optim.Optimizer) -> Tuple[nn.Module, torch.optim.Optimizer]:\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, 'checkpoint.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "puyQaj1KXMW7"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(model: nn.Module, optimizer: torch.optim.Optimizer) -> None:\n",
        "    checkpoint = torch.load('checkpoint.pt')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "l_Z-eIVoExOB"
      },
      "outputs": [],
      "source": [
        "def get_data_loaders(\n",
        "        num_classes: int,\n",
        "        use_pseudo_labelling: bool,\n",
        "        labelled_data_ratio: float,\n",
        "        batch_size: int,\n",
        "        unlabelled_batch_size: int,\n",
        "        device: str,\n",
        "        ) -> Tuple[DataLoader, DataLoader, DataLoader, Optional[DataLoader]]:\n",
        "    filenames_trainval, labels_trainval = get_image_names_and_labels('annotations/trainval.txt', num_classes=num_classes)\n",
        "    filenames_test, labels_test = get_image_names_and_labels('annotations/test.txt', num_classes=num_classes)\n",
        "    filenames_train, filenames_val, labels_train, labels_val = train_test_split(filenames_trainval, labels_trainval, test_size=0.2, stratify=labels_trainval)\n",
        "\n",
        "    if use_pseudo_labelling:\n",
        "        filenames_train, unlabelled_filenames_train, labels_train, _ = train_test_split(\n",
        "            filenames_train, labels_train, train_size=labelled_data_ratio, stratify=labels_train\n",
        "        )\n",
        "        dataset_train = ImageDataset(filenames_train, labels_train, use_augmentations=True, device=device)\n",
        "        unlabelled_dataset_train = UnlabelledImageDataset(unlabelled_filenames_train, use_augmentations=True, device=device)\n",
        "        unlabelled_train_data_loader = DataLoader(unlabelled_dataset_train, batch_size=unlabelled_batch_size, shuffle=True)\n",
        "    else:\n",
        "        dataset_train = ImageDataset(filenames_train, labels_train, use_augmentations=True, device=device)\n",
        "        unlabelled_train_data_loader = None\n",
        "\n",
        "    dataset_train = ImageDataset(filenames_train, labels_train, use_augmentations=True, device=device)\n",
        "    dataset_val = ImageDataset(filenames_val, labels_val, use_augmentations=False, device=device)\n",
        "    dataset_test = ImageDataset(filenames_test, labels_test, use_augmentations=False, device=device)\n",
        "\n",
        "    train_data_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "    val_data_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
        "    test_data_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_data_loader, val_data_loader, test_data_loader, unlabelled_train_data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_get_max_val_accuracy(config: Config) -> float:\n",
        "    model, model_trainable_layers = get_pretrained_model_and_model_trainable_layers(config.num_classes, config.device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model_trainable_layers[-1].parameters(),\n",
        "        lr=config.last_layers_training_configs[0].lr,\n",
        "        weight_decay=config.last_layers_training_configs[0].weight_decay,\n",
        "    )\n",
        "\n",
        "    train_data_loader, val_data_loader, test_data_loader, unlabelled_train_data_loader = get_data_loaders(\n",
        "        config.num_classes,\n",
        "        config.use_pseudo_labelling,\n",
        "        config.labelled_data_ratio,\n",
        "        config.batch_size,\n",
        "        config.unlabelled_batch_size,\n",
        "        config.device,\n",
        "        \n",
        "    )\n",
        "    assert isinstance(unlabelled_train_data_loader, DataLoader)\n",
        "\n",
        "    max_val_accuracy = float('-inf')\n",
        "    argmax_epoch = -1\n",
        "\n",
        "    # for epoch in range(config.max_num_epochs):\n",
        "    for epoch in tqdm(list(range(config.max_num_epochs))):\n",
        "        # print(f'Epoch #{epoch}:')\n",
        "        train_loss = train_single_epoch_pseudo(\n",
        "            model, model_trainable_layers, train_data_loader, unlabelled_train_data_loader, criterion, optimizer, config.last_layers_training_configs,\n",
        "            epoch, config.T_1, config.T_2, config.ALPHA_F,\n",
        "        )\n",
        "        # print(f'Train loss: {train_loss}')\n",
        "        val_accuracy = get_model_accuracy(model, val_data_loader)\n",
        "        if val_accuracy > max_val_accuracy:\n",
        "            # print(f'Validation accuracy: {100 * val_accuracy:.2f}% (new best)')\n",
        "            max_val_accuracy = val_accuracy\n",
        "            argmax_epoch = epoch\n",
        "            # save_checkpoint(model, optimizer)\n",
        "            # print('Checkpoint saved')\n",
        "        else:\n",
        "            # print(f'Validation accuracy: {100 * val_accuracy:.2f}% (worse than {100 * max_val_accuracy:.2f}% of epoch {argmax_epoch})')\n",
        "            if epoch > argmax_epoch + config.patience:\n",
        "                # print(f'Early stopping')\n",
        "                break\n",
        "        # # Start training earlier layers\n",
        "        # if epoch == config.train_earlier_layers_delay and config.n_hidden_layers_to_train > 0:\n",
        "        #     print (f'Making last {config.n_hidden_layers_to_train} hidden layers trainable')\n",
        "        #     make_hidden_layers_trainable(model, config.n_hidden_layers_to_train)\n",
        "        #     optimizer = torch.optim.Adam(model.parameters(), lr=config.adam_optimizer_config.lr / 100, weight_decay=config.adam_optimizer_config.weight_decay)\n",
        "        # print()\n",
        "    return max_val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYVA1JYkN0ZB",
        "outputId": "d0ab9637-378d-402f-d24e-a94f19ff11c1"
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial):\n",
        "    batch_size_exp = trial.suggest_int(\"batch_size_exp\", 3, 7)\n",
        "    unlabelled_batch_size_exp = trial.suggest_int(\"unlabelled_batch_size_exp\", 3, 7)\n",
        "    batch_size = 2 ** batch_size_exp\n",
        "    unlabelled_batch_size = 2 ** unlabelled_batch_size_exp\n",
        "    T_1 = trial.suggest_int(\"T_1\", 1, 30)\n",
        "    T_2 = trial.suggest_int(\"T_2\", T_1 + 1, 60)\n",
        "    ALPHA_F_exp = trial.suggest_float(\"ALPHA_F_exp\", -2.0, 2.0)\n",
        "    ALPHA_F = 10.0 ** ALPHA_F_exp\n",
        "    config = Config(\n",
        "        device='cuda:0',\n",
        "        num_classes=37,\n",
        "        batch_size=batch_size,\n",
        "        max_num_epochs=100,\n",
        "        patience=10,\n",
        "        last_layers_training_configs=[],\n",
        "        # pseudo-labeling\n",
        "        use_pseudo_labelling=1,\n",
        "        labelled_data_ratio=0.1,\n",
        "        T_1=T_1,  # 1_000\n",
        "        T_2=T_2,  # 1_000\n",
        "        ALPHA_F=ALPHA_F,  # 3\n",
        "        unlabelled_batch_size=unlabelled_batch_size,\n",
        "    )\n",
        "    last_layer_lr_exp = trial.suggest_float(\"last_layer_lr_exp\", -4.0, -2.0)\n",
        "    last_layer_weight_decay_exp = trial.suggest_float(\"last_layer_weight_decay_exp\", -4.0, -2.0)\n",
        "    last_layer_lr = 10.0 ** last_layer_lr_exp\n",
        "    last_layer_weight_decay = 10.0 ** last_layer_weight_decay_exp\n",
        "    config.last_layers_training_configs.append(LastLayerTrainingConfig(\n",
        "        unfreeze_epoch=0,\n",
        "        lr=last_layer_lr,\n",
        "        weight_decay=last_layer_weight_decay,\n",
        "        use_train_mode=True,\n",
        "    ))\n",
        "    second_last_layer_unfreeze_epoch = trial.suggest_int(\"second_last_layer_unfreeze_epoch\", 1, 10)\n",
        "    second_last_layer_lr_exp = trial.suggest_float(\"second_last_layer_lr_exp\", -5.0, -1.0)\n",
        "    second_last_layer_weight_decay_exp = trial.suggest_float(\"second_last_layer_weight_decay_exp\", -5.0, -1.0)\n",
        "    second_last_layer_lr = 10.0 ** second_last_layer_lr_exp\n",
        "    second_last_layer_weight_decay = 10.0 ** second_last_layer_weight_decay_exp\n",
        "    config.last_layers_training_configs.append(LastLayerTrainingConfig(\n",
        "        unfreeze_epoch=second_last_layer_unfreeze_epoch,\n",
        "        lr=second_last_layer_lr,\n",
        "        weight_decay=second_last_layer_weight_decay,\n",
        "        use_train_mode=True,\n",
        "    ))\n",
        "    third_last_layer_unfreeze_epoch = trial.suggest_int(\"third_last_layer_unfreeze_epoch\", second_last_layer_unfreeze_epoch, 15)\n",
        "    third_last_layer_lr_exp = trial.suggest_float(\"third_last_layer_lr_exp\", -5.0, -1.0)\n",
        "    third_last_layer_weight_decay_exp = trial.suggest_float(\"third_last_layer_weight_decay_exp\", -5.0, -1.0)\n",
        "    third_last_layer_lr = 10.0 ** third_last_layer_lr_exp\n",
        "    third_last_layer_weight_decay = 10.0 ** third_last_layer_weight_decay_exp\n",
        "    config.last_layers_training_configs.append(LastLayerTrainingConfig(\n",
        "        unfreeze_epoch=third_last_layer_unfreeze_epoch,\n",
        "        lr=third_last_layer_lr,\n",
        "        weight_decay=third_last_layer_weight_decay,\n",
        "        use_train_mode=True,\n",
        "    ))\n",
        "    return train_and_get_max_val_accuracy(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-24 07:22:38,257] A new study created in memory with name: no-name-593a90bf-1d98-466a-909b-435f3c20a0b9\n",
            " 13%|█▎        | 13/100 [00:58<06:33,  4.53s/it]\n",
            "[I 2024-05-24 07:23:37,413] Trial 0 finished with value: 0.25679346919059753 and parameters: {'batch_size_exp': 7, 'unlabelled_batch_size_exp': 4, 'T_1': 2, 'T_2': 19, 'ALPHA_F_exp': 1.609556906321632, 'last_layer_lr_exp': -3.0121971398823826, 'last_layer_weight_decay_exp': -2.0848795855724744, 'second_last_layer_unfreeze_epoch': 8, 'second_last_layer_lr_exp': -1.629507688307899, 'second_last_layer_weight_decay_exp': -3.3468064319548483, 'third_last_layer_unfreeze_epoch': 15, 'third_last_layer_lr_exp': -2.927638952220023, 'third_last_layer_weight_decay_exp': -1.4510043759696747}. Best is trial 0 with value: 0.25679346919059753.\n",
            " 28%|██▊       | 28/100 [02:27<06:18,  5.26s/it]\n",
            "[I 2024-05-24 07:26:04,873] Trial 1 finished with value: 0.875 and parameters: {'batch_size_exp': 5, 'unlabelled_batch_size_exp': 6, 'T_1': 24, 'T_2': 43, 'ALPHA_F_exp': -0.23038433252921608, 'last_layer_lr_exp': -2.197113990937915, 'last_layer_weight_decay_exp': -2.56138838524553, 'second_last_layer_unfreeze_epoch': 6, 'second_last_layer_lr_exp': -3.4498309186106084, 'second_last_layer_weight_decay_exp': -2.0669902496908175, 'third_last_layer_unfreeze_epoch': 10, 'third_last_layer_lr_exp': -4.973003336982554, 'third_last_layer_weight_decay_exp': -3.371582770942014}. Best is trial 1 with value: 0.875.\n",
            " 35%|███▌      | 35/100 [03:29<06:28,  5.98s/it]\n",
            "[I 2024-05-24 07:29:34,557] Trial 2 finished with value: 0.864130437374115 and parameters: {'batch_size_exp': 4, 'unlabelled_batch_size_exp': 4, 'T_1': 21, 'T_2': 43, 'ALPHA_F_exp': -0.5744705122364122, 'last_layer_lr_exp': -3.4710239083297494, 'last_layer_weight_decay_exp': -2.879034831624769, 'second_last_layer_unfreeze_epoch': 8, 'second_last_layer_lr_exp': -4.846220182991345, 'second_last_layer_weight_decay_exp': -3.5286126119367482, 'third_last_layer_unfreeze_epoch': 15, 'third_last_layer_lr_exp': -3.3635777860939644, 'third_last_layer_weight_decay_exp': -4.671334791228165}. Best is trial 1 with value: 0.875.\n",
            " 29%|██▉       | 29/100 [08:21<20:27, 17.29s/it]\n",
            "[I 2024-05-24 07:37:56,245] Trial 3 finished with value: 0.8804348111152649 and parameters: {'batch_size_exp': 3, 'unlabelled_batch_size_exp': 7, 'T_1': 12, 'T_2': 46, 'ALPHA_F_exp': -0.9959095602612575, 'last_layer_lr_exp': -3.4122304845877927, 'last_layer_weight_decay_exp': -2.7775279559334773, 'second_last_layer_unfreeze_epoch': 3, 'second_last_layer_lr_exp': -2.717205744619768, 'second_last_layer_weight_decay_exp': -1.292585341450204, 'third_last_layer_unfreeze_epoch': 6, 'third_last_layer_lr_exp': -4.62762864658291, 'third_last_layer_weight_decay_exp': -4.185108187096757}. Best is trial 3 with value: 0.8804348111152649.\n",
            " 17%|█▋        | 17/100 [01:21<06:37,  4.79s/it]\n",
            "[I 2024-05-24 07:39:17,916] Trial 4 finished with value: 0.8722826242446899 and parameters: {'batch_size_exp': 5, 'unlabelled_batch_size_exp': 6, 'T_1': 18, 'T_2': 26, 'ALPHA_F_exp': 1.4460156455137083, 'last_layer_lr_exp': -2.422011612087452, 'last_layer_weight_decay_exp': -3.104604801688841, 'second_last_layer_unfreeze_epoch': 2, 'second_last_layer_lr_exp': -2.5889971642900504, 'second_last_layer_weight_decay_exp': -2.92613907187203, 'third_last_layer_unfreeze_epoch': 3, 'third_last_layer_lr_exp': -4.106941839249685, 'third_last_layer_weight_decay_exp': -3.42297844074595}. Best is trial 3 with value: 0.8804348111152649.\n",
            " 53%|█████▎    | 53/100 [05:18<04:42,  6.01s/it]\n",
            "[I 2024-05-24 07:44:36,647] Trial 5 finished with value: 0.9008152484893799 and parameters: {'batch_size_exp': 4, 'unlabelled_batch_size_exp': 3, 'T_1': 4, 'T_2': 31, 'ALPHA_F_exp': -0.38376601420330436, 'last_layer_lr_exp': -3.247879364739568, 'last_layer_weight_decay_exp': -3.2077083836002087, 'second_last_layer_unfreeze_epoch': 5, 'second_last_layer_lr_exp': -3.269623161247074, 'second_last_layer_weight_decay_exp': -2.764352099748744, 'third_last_layer_unfreeze_epoch': 12, 'third_last_layer_lr_exp': -4.107934074285204, 'third_last_layer_weight_decay_exp': -3.9823413003427537}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 22%|██▏       | 22/100 [01:45<06:13,  4.79s/it]\n",
            "[I 2024-05-24 07:46:22,322] Trial 6 finished with value: 0.6413043737411499 and parameters: {'batch_size_exp': 5, 'unlabelled_batch_size_exp': 3, 'T_1': 24, 'T_2': 56, 'ALPHA_F_exp': -0.4408129380434165, 'last_layer_lr_exp': -3.671867798089208, 'last_layer_weight_decay_exp': -2.840499724524304, 'second_last_layer_unfreeze_epoch': 3, 'second_last_layer_lr_exp': -1.4751950670579332, 'second_last_layer_weight_decay_exp': -2.685336319235761, 'third_last_layer_unfreeze_epoch': 9, 'third_last_layer_lr_exp': -1.0737505695365153, 'third_last_layer_weight_decay_exp': -2.7795953437010152}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 32%|███▏      | 32/100 [02:31<05:22,  4.74s/it]\n",
            "[I 2024-05-24 07:48:54,224] Trial 7 finished with value: 0.8926630616188049 and parameters: {'batch_size_exp': 7, 'unlabelled_batch_size_exp': 6, 'T_1': 14, 'T_2': 49, 'ALPHA_F_exp': -1.3762451183270903, 'last_layer_lr_exp': -3.841516126643981, 'last_layer_weight_decay_exp': -3.8827585079573907, 'second_last_layer_unfreeze_epoch': 10, 'second_last_layer_lr_exp': -4.6467615343516115, 'second_last_layer_weight_decay_exp': -4.840420464962486, 'third_last_layer_unfreeze_epoch': 13, 'third_last_layer_lr_exp': -1.7371557949997052, 'third_last_layer_weight_decay_exp': -3.4279566761699583}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 16%|█▌        | 16/100 [01:20<07:03,  5.04s/it]\n",
            "[I 2024-05-24 07:50:15,012] Trial 8 finished with value: 0.811141312122345 and parameters: {'batch_size_exp': 7, 'unlabelled_batch_size_exp': 7, 'T_1': 11, 'T_2': 15, 'ALPHA_F_exp': 1.3413257091694688, 'last_layer_lr_exp': -2.2197343921702553, 'last_layer_weight_decay_exp': -3.426615952244154, 'second_last_layer_unfreeze_epoch': 3, 'second_last_layer_lr_exp': -1.5782353499561927, 'second_last_layer_weight_decay_exp': -3.5178679334415293, 'third_last_layer_unfreeze_epoch': 7, 'third_last_layer_lr_exp': -1.0606817863626978, 'third_last_layer_weight_decay_exp': -1.1536356511723338}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 20%|██        | 20/100 [05:59<23:58, 17.98s/it]\n",
            "[I 2024-05-24 07:56:14,815] Trial 9 finished with value: 0.86277174949646 and parameters: {'batch_size_exp': 3, 'unlabelled_batch_size_exp': 7, 'T_1': 8, 'T_2': 24, 'ALPHA_F_exp': 1.6817216940270718, 'last_layer_lr_exp': -3.5161558682628433, 'last_layer_weight_decay_exp': -2.558405742309523, 'second_last_layer_unfreeze_epoch': 2, 'second_last_layer_lr_exp': -2.6921122030213236, 'second_last_layer_weight_decay_exp': -4.215676699760488, 'third_last_layer_unfreeze_epoch': 3, 'third_last_layer_lr_exp': -3.3086809669055235, 'third_last_layer_weight_decay_exp': -3.519835248723151}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 12%|█▏        | 12/100 [01:16<09:23,  6.40s/it]\n",
            "[I 2024-05-24 07:57:31,865] Trial 10 finished with value: 0.6508152484893799 and parameters: {'batch_size_exp': 4, 'unlabelled_batch_size_exp': 3, 'T_1': 1, 'T_2': 2, 'ALPHA_F_exp': 0.5642647595620336, 'last_layer_lr_exp': -2.7476439467610927, 'last_layer_weight_decay_exp': -3.493531790823584, 'second_last_layer_unfreeze_epoch': 5, 'second_last_layer_lr_exp': -3.75294775364325, 'second_last_layer_weight_decay_exp': -1.9111134594571166, 'third_last_layer_unfreeze_epoch': 12, 'third_last_layer_lr_exp': -2.3339910017160603, 'third_last_layer_weight_decay_exp': -2.412566963057591}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 29%|██▉       | 29/100 [02:16<05:33,  4.70s/it]\n",
            "[I 2024-05-24 07:59:48,300] Trial 11 finished with value: 0.8614130616188049 and parameters: {'batch_size_exp': 6, 'unlabelled_batch_size_exp': 5, 'T_1': 30, 'T_2': 51, 'ALPHA_F_exp': -1.8497535225696349, 'last_layer_lr_exp': -3.9841522930361766, 'last_layer_weight_decay_exp': -3.9784258434936133, 'second_last_layer_unfreeze_epoch': 6, 'second_last_layer_lr_exp': -4.983519134242786, 'second_last_layer_weight_decay_exp': -4.942075306396417, 'third_last_layer_unfreeze_epoch': 13, 'third_last_layer_lr_exp': -1.9170869770306314, 'third_last_layer_weight_decay_exp': -4.1709574243742}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 46%|████▌     | 46/100 [04:00<04:42,  5.24s/it]\n",
            "[I 2024-05-24 08:03:49,526] Trial 12 finished with value: 0.876358687877655 and parameters: {'batch_size_exp': 6, 'unlabelled_batch_size_exp': 5, 'T_1': 6, 'T_2': 33, 'ALPHA_F_exp': -1.4561766761170167, 'last_layer_lr_exp': -3.101294300692037, 'last_layer_weight_decay_exp': -3.947199039001371, 'second_last_layer_unfreeze_epoch': 10, 'second_last_layer_lr_exp': -4.200298388881281, 'second_last_layer_weight_decay_exp': -4.983929762257562, 'third_last_layer_unfreeze_epoch': 13, 'third_last_layer_lr_exp': -4.057890429531221, 'third_last_layer_weight_decay_exp': -2.228228683789096}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 30%|███       | 30/100 [03:55<09:09,  7.86s/it]\n",
            "[I 2024-05-24 08:07:45,448] Trial 13 finished with value: 0.8709239363670349 and parameters: {'batch_size_exp': 4, 'unlabelled_batch_size_exp': 6, 'T_1': 15, 'T_2': 35, 'ALPHA_F_exp': 0.3708746761637909, 'last_layer_lr_exp': -3.9090659680729187, 'last_layer_weight_decay_exp': -3.5575406793547697, 'second_last_layer_unfreeze_epoch': 9, 'second_last_layer_lr_exp': -4.198086933742028, 'second_last_layer_weight_decay_exp': -4.150270584061587, 'third_last_layer_unfreeze_epoch': 13, 'third_last_layer_lr_exp': -1.9095052914956203, 'third_last_layer_weight_decay_exp': -4.186986577931256}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 46%|████▌     | 46/100 [03:44<04:23,  4.89s/it]\n",
            "[I 2024-05-24 08:11:30,550] Trial 14 finished with value: 0.895380437374115 and parameters: {'batch_size_exp': 6, 'unlabelled_batch_size_exp': 4, 'T_1': 6, 'T_2': 35, 'ALPHA_F_exp': -1.239672935088623, 'last_layer_lr_exp': -3.199158727919653, 'last_layer_weight_decay_exp': -3.2312655246911928, 'second_last_layer_unfreeze_epoch': 5, 'second_last_layer_lr_exp': -2.1728067213426243, 'second_last_layer_weight_decay_exp': -2.457427173389928, 'third_last_layer_unfreeze_epoch': 11, 'third_last_layer_lr_exp': -3.9060977797569807, 'third_last_layer_weight_decay_exp': -4.738745413914794}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 44%|████▍     | 44/100 [03:36<04:35,  4.92s/it]\n",
            "[I 2024-05-24 08:15:07,325] Trial 15 finished with value: 0.88722825050354 and parameters: {'batch_size_exp': 6, 'unlabelled_batch_size_exp': 4, 'T_1': 6, 'T_2': 35, 'ALPHA_F_exp': -0.901555825531349, 'last_layer_lr_exp': -3.2038717858218995, 'last_layer_weight_decay_exp': -3.1761705256010018, 'second_last_layer_unfreeze_epoch': 5, 'second_last_layer_lr_exp': -2.2219966073074793, 'second_last_layer_weight_decay_exp': -2.359309226749399, 'third_last_layer_unfreeze_epoch': 11, 'third_last_layer_lr_exp': -4.024544199651668, 'third_last_layer_weight_decay_exp': -4.900567320679997}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 19%|█▉        | 19/100 [01:56<08:18,  6.15s/it]\n",
            "[I 2024-05-24 08:17:04,494] Trial 16 finished with value: 0.851902186870575 and parameters: {'batch_size_exp': 4, 'unlabelled_batch_size_exp': 3, 'T_1': 5, 'T_2': 28, 'ALPHA_F_exp': 0.4803991076967917, 'last_layer_lr_exp': -2.705581542952406, 'last_layer_weight_decay_exp': -3.281842657816875, 'second_last_layer_unfreeze_epoch': 4, 'second_last_layer_lr_exp': -3.2007931760409765, 'second_last_layer_weight_decay_exp': -1.5646891413751542, 'third_last_layer_unfreeze_epoch': 9, 'third_last_layer_lr_exp': -3.644214037460075, 'third_last_layer_weight_decay_exp': -4.472493739173395}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 29%|██▉       | 29/100 [02:22<05:49,  4.92s/it]\n",
            "[I 2024-05-24 08:19:27,501] Trial 17 finished with value: 0.875 and parameters: {'batch_size_exp': 6, 'unlabelled_batch_size_exp': 4, 'T_1': 9, 'T_2': 39, 'ALPHA_F_exp': 0.03295164965843034, 'last_layer_lr_exp': -2.7509365903260417, 'last_layer_weight_decay_exp': -3.685939540289162, 'second_last_layer_unfreeze_epoch': 7, 'second_last_layer_lr_exp': -1.0001649323721438, 'second_last_layer_weight_decay_exp': -2.5079727356725914, 'third_last_layer_unfreeze_epoch': 11, 'third_last_layer_lr_exp': -4.506655120795832, 'third_last_layer_weight_decay_exp': -3.8471541902950506}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 37%|███▋      | 37/100 [04:01<06:50,  6.52s/it]\n",
            "[I 2024-05-24 08:23:29,149] Trial 18 finished with value: 0.8573369979858398 and parameters: {'batch_size_exp': 3, 'unlabelled_batch_size_exp': 3, 'T_1': 3, 'T_2': 12, 'ALPHA_F_exp': -1.962809179866853, 'last_layer_lr_exp': -3.2447320092199443, 'last_layer_weight_decay_exp': -2.072634751747142, 'second_last_layer_unfreeze_epoch': 1, 'second_last_layer_lr_exp': -2.015444728553592, 'second_last_layer_weight_decay_exp': -1.0164458019167477, 'third_last_layer_unfreeze_epoch': 5, 'third_last_layer_lr_exp': -2.842250056272621, 'third_last_layer_weight_decay_exp': -4.9061849606958985}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 42%|████▏     | 42/100 [03:50<05:18,  5.48s/it]\n",
            "[I 2024-05-24 08:27:19,744] Trial 19 finished with value: 0.89402174949646 and parameters: {'batch_size_exp': 5, 'unlabelled_batch_size_exp': 4, 'T_1': 9, 'T_2': 30, 'ALPHA_F_exp': -0.9938013401446955, 'last_layer_lr_exp': -2.824729385988223, 'last_layer_weight_decay_exp': -3.3100103400075405, 'second_last_layer_unfreeze_epoch': 4, 'second_last_layer_lr_exp': -3.099951631772691, 'second_last_layer_weight_decay_exp': -3.0756021795043025, 'third_last_layer_unfreeze_epoch': 8, 'third_last_layer_lr_exp': -3.80878398819529, 'third_last_layer_weight_decay_exp': -3.759824687863601}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 18%|█▊        | 18/100 [01:37<07:25,  5.43s/it]\n",
            "[I 2024-05-24 08:28:57,760] Trial 20 finished with value: 0.875 and parameters: {'batch_size_exp': 5, 'unlabelled_batch_size_exp': 3, 'T_1': 4, 'T_2': 22, 'ALPHA_F_exp': -1.4406636037460498, 'last_layer_lr_exp': -2.5016770327640936, 'last_layer_weight_decay_exp': -2.6103691463605987, 'second_last_layer_unfreeze_epoch': 7, 'second_last_layer_lr_exp': -2.128959980201566, 'second_last_layer_weight_decay_exp': -2.1261588856897164, 'third_last_layer_unfreeze_epoch': 12, 'third_last_layer_lr_exp': -4.45314115140291, 'third_last_layer_weight_decay_exp': -2.8754140832774735}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 52%|█████▏    | 52/100 [04:42<04:21,  5.44s/it]\n",
            "[I 2024-05-24 08:33:40,889] Trial 21 finished with value: 0.876358687877655 and parameters: {'batch_size_exp': 5, 'unlabelled_batch_size_exp': 4, 'T_1': 9, 'T_2': 29, 'ALPHA_F_exp': -0.9192163037896957, 'last_layer_lr_exp': -2.8995863451792405, 'last_layer_weight_decay_exp': -3.317599419026487, 'second_last_layer_unfreeze_epoch': 4, 'second_last_layer_lr_exp': -3.2223716843359247, 'second_last_layer_weight_decay_exp': -3.1077724989196978, 'third_last_layer_unfreeze_epoch': 8, 'third_last_layer_lr_exp': -3.7300691050427495, 'third_last_layer_weight_decay_exp': -3.832550551553835}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 30%|███       | 30/100 [03:10<07:25,  6.36s/it]\n",
            "[I 2024-05-24 08:36:52,066] Trial 22 finished with value: 0.8817934989929199 and parameters: {'batch_size_exp': 4, 'unlabelled_batch_size_exp': 4, 'T_1': 11, 'T_2': 39, 'ALPHA_F_exp': -0.7015475483558902, 'last_layer_lr_exp': -3.3084778728245565, 'last_layer_weight_decay_exp': -3.0088470298817103, 'second_last_layer_unfreeze_epoch': 4, 'second_last_layer_lr_exp': -3.679120850941235, 'second_last_layer_weight_decay_exp': -2.813711549754788, 'third_last_layer_unfreeze_epoch': 10, 'third_last_layer_lr_exp': -3.750091486659933, 'third_last_layer_weight_decay_exp': -4.3900576265984}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 34%|███▍      | 34/100 [02:57<05:45,  5.23s/it]\n",
            "[I 2024-05-24 08:39:50,107] Trial 23 finished with value: 0.89402174949646 and parameters: {'batch_size_exp': 6, 'unlabelled_batch_size_exp': 5, 'T_1': 8, 'T_2': 31, 'ALPHA_F_exp': -1.2002297627685832, 'last_layer_lr_exp': -2.9029845205584044, 'last_layer_weight_decay_exp': -3.7567697725103972, 'second_last_layer_unfreeze_epoch': 5, 'second_last_layer_lr_exp': -2.926628327095382, 'second_last_layer_weight_decay_exp': -4.003948988359484, 'third_last_layer_unfreeze_epoch': 8, 'third_last_layer_lr_exp': -3.371180871777497, 'third_last_layer_weight_decay_exp': -3.919277007664328}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 31%|███       | 31/100 [02:34<05:44,  4.99s/it]\n",
            "[I 2024-05-24 08:42:25,204] Trial 24 finished with value: 0.876358687877655 and parameters: {'batch_size_exp': 6, 'unlabelled_batch_size_exp': 4, 'T_1': 1, 'T_2': 38, 'ALPHA_F_exp': -0.0012057170665542571, 'last_layer_lr_exp': -3.099738174255696, 'last_layer_weight_decay_exp': -3.1852977322714895, 'second_last_layer_unfreeze_epoch': 4, 'second_last_layer_lr_exp': -2.422481548501316, 'second_last_layer_weight_decay_exp': -3.0634691895121224, 'third_last_layer_unfreeze_epoch': 11, 'third_last_layer_lr_exp': -4.25299829975278, 'third_last_layer_weight_decay_exp': -4.672445888888114}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 43%|████▎     | 43/100 [04:18<05:42,  6.01s/it]\n",
            "[I 2024-05-24 08:46:43,775] Trial 25 finished with value: 0.8790761232376099 and parameters: {'batch_size_exp': 4, 'unlabelled_batch_size_exp': 3, 'T_1': 6, 'T_2': 20, 'ALPHA_F_exp': -1.7639489301208722, 'last_layer_lr_exp': -3.621140899896364, 'last_layer_weight_decay_exp': -3.366992913572584, 'second_last_layer_unfreeze_epoch': 6, 'second_last_layer_lr_exp': -3.0477687985544466, 'second_last_layer_weight_decay_exp': -2.377257778573705, 'third_last_layer_unfreeze_epoch': 12, 'third_last_layer_lr_exp': -4.818888820704146, 'third_last_layer_weight_decay_exp': -3.743588592678675}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 18%|█▊        | 18/100 [01:37<07:25,  5.43s/it]\n",
            "[I 2024-05-24 08:48:21,869] Trial 26 finished with value: 0.8600543737411499 and parameters: {'batch_size_exp': 5, 'unlabelled_batch_size_exp': 5, 'T_1': 13, 'T_2': 32, 'ALPHA_F_exp': 0.963066457905726, 'last_layer_lr_exp': -2.577724499713268, 'last_layer_weight_decay_exp': -2.9927114714942706, 'second_last_layer_unfreeze_epoch': 7, 'second_last_layer_lr_exp': -3.9295838126152036, 'second_last_layer_weight_decay_exp': -3.868019878717872, 'third_last_layer_unfreeze_epoch': 14, 'third_last_layer_lr_exp': -3.773896594873895, 'third_last_layer_weight_decay_exp': -4.5026360889140005}. Best is trial 5 with value: 0.9008152484893799.\n",
            " 25%|██▌       | 25/100 [02:08<06:25,  5.14s/it]\n",
            "[I 2024-05-24 08:50:30,536] Trial 27 finished with value: 0.85597825050354 and parameters: {'batch_size_exp': 5, 'unlabelled_batch_size_exp': 3, 'T_1': 4, 'T_2': 26, 'ALPHA_F_exp': -0.271803814005357, 'last_layer_lr_exp': -2.9095667268958096, 'last_layer_weight_decay_exp': -3.582703307819714, 'second_last_layer_unfreeze_epoch': 5, 'second_last_layer_lr_exp': -3.401476123107637, 'second_last_layer_weight_decay_exp': -1.7186878951247522, 'third_last_layer_unfreeze_epoch': 10, 'third_last_layer_lr_exp': -2.6533890432591907, 'third_last_layer_weight_decay_exp': -3.0217431642851817}. Best is trial 5 with value: 0.9008152484893799.\n",
            "  2%|▏         | 2/100 [00:09<07:50,  4.80s/it]\n",
            "[W 2024-05-24 08:50:40,398] Trial 28 failed with parameters: {'batch_size_exp': 5, 'unlabelled_batch_size_exp': 4, 'T_1': 18, 'T_2': 37, 'ALPHA_F_exp': -1.209880724360397, 'last_layer_lr_exp': -3.2572994592482765, 'last_layer_weight_decay_exp': -3.008946894035909, 'second_last_layer_unfreeze_epoch': 2, 'second_last_layer_lr_exp': -2.932475344257206, 'second_last_layer_weight_decay_exp': -3.3678510004187765, 'third_last_layer_unfreeze_epoch': 5, 'third_last_layer_lr_exp': -3.1382552107902244, 'third_last_layer_weight_decay_exp': -4.076074019741807} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_22432\\4103625142.py\", line 57, in objective\n",
            "    return train_and_get_max_val_accuracy(config)\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_22432\\3826457440.py\", line 28, in train_and_get_max_val_accuracy\n",
            "    train_loss = train_single_epoch_pseudo(\n",
            "  File \"C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_22432\\3171306822.py\", line 56, in train_single_epoch_pseudo\n",
            "    if not np.isnan(labelled_loss.item()):\n",
            "KeyboardInterrupt\n",
            "[W 2024-05-24 08:50:40,399] Trial 28 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\georg\\anaconda3\\envs\\kth_deep_learning_project\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[32], line 57\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     50\u001b[0m third_last_layer_weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m third_last_layer_weight_decay_exp\n\u001b[0;32m     51\u001b[0m config\u001b[38;5;241m.\u001b[39mlast_layers_training_configs\u001b[38;5;241m.\u001b[39mappend(LastLayerTrainingConfig(\n\u001b[0;32m     52\u001b[0m     unfreeze_epoch\u001b[38;5;241m=\u001b[39mthird_last_layer_unfreeze_epoch,\n\u001b[0;32m     53\u001b[0m     lr\u001b[38;5;241m=\u001b[39mthird_last_layer_lr,\n\u001b[0;32m     54\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mthird_last_layer_weight_decay,\n\u001b[0;32m     55\u001b[0m     use_train_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     56\u001b[0m ))\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_and_get_max_val_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[26], line 28\u001b[0m, in \u001b[0;36mtrain_and_get_max_val_accuracy\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# for epoch in range(config.max_num_epochs):\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mmax_num_epochs))):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# print(f'Epoch #{epoch}:')\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_single_epoch_pseudo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_trainable_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlabelled_train_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_layers_training_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALPHA_F\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# print(f'Train loss: {train_loss}')\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     val_accuracy \u001b[38;5;241m=\u001b[39m get_model_accuracy(model, val_data_loader)\n",
            "Cell \u001b[1;32mIn[22], line 56\u001b[0m, in \u001b[0;36mtrain_single_epoch_pseudo\u001b[1;34m(model, model_trainable_layers, train_data_loader, unlabelled_train_data_loader, criterion, optimizer, last_layers_training_configs, epoch, T_1, T_2, ALPHA_F)\u001b[0m\n\u001b[0;32m     54\u001b[0m labelled_outputs \u001b[38;5;241m=\u001b[39m model(labelled_inputs)\n\u001b[0;32m     55\u001b[0m labelled_loss \u001b[38;5;241m=\u001b[39m criterion(labelled_outputs, labelled_labels)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(\u001b[43mlabelled_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     57\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labelled_loss\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m T_1:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FrozenTrial(number=31, state=TrialState.COMPLETE, values=[0.904891312122345], datetime_start=datetime.datetime(2024, 5, 24, 3, 17, 7, 298202), datetime_complete=datetime.datetime(2024, 5, 24, 3, 21, 8, 100381), params={'batch_size_exp': 6, 'unlabelled_batch_size_exp': 7, 'T_1': 22, 'T_2': 30, 'ALPHA_F_exp': -1.9186627229256172, 'last_layer_lr_exp': -3.437742747579238, 'last_layer_weight_decay_exp': -3.8574542923939004, 'second_last_layer_unfreeze_epoch': 6, 'second_last_layer_lr_exp': -4.205220815004278, 'second_last_layer_weight_decay_exp': -3.818874540626863, 'third_last_layer_unfreeze_epoch': 8, 'third_last_layer_lr_exp': -3.03043588451279, 'third_last_layer_weight_decay_exp': -4.190767281932155}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size_exp': IntDistribution(high=7, log=False, low=3, step=1), 'unlabelled_batch_size_exp': IntDistribution(high=7, log=False, low=3, step=1), 'T_1': IntDistribution(high=30, log=False, low=1, step=1), 'T_2': IntDistribution(high=60, log=False, low=23, step=1), 'ALPHA_F_exp': FloatDistribution(high=2.0, log=False, low=-2.0, step=None), 'last_layer_lr_exp': FloatDistribution(high=-2.0, log=False, low=-4.0, step=None), 'last_layer_weight_decay_exp': FloatDistribution(high=-2.0, log=False, low=-4.0, step=None), 'second_last_layer_unfreeze_epoch': IntDistribution(high=10, log=False, low=1, step=1), 'second_last_layer_lr_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None), 'second_last_layer_weight_decay_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None), 'third_last_layer_unfreeze_epoch': IntDistribution(high=15, log=False, low=6, step=1), 'third_last_layer_lr_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None), 'third_last_layer_weight_decay_exp': FloatDistribution(high=-1.0, log=False, low=-5.0, step=None)}, trial_id=31, value=None)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR85iuaLXMW9",
        "outputId": "0f984362-01e7-47f8-cdb4-310d5ef63e17"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m load_checkpoint(\u001b[43mmodel\u001b[49m, optimizer)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheckpoint loaded\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m get_model_accuracy(model, test_data_loader)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "load_checkpoint(model, optimizer)\n",
        "print('Checkpoint loaded')\n",
        "\n",
        "test_accuracy = get_model_accuracy(model, test_data_loader)\n",
        "\n",
        "print(f'Test accuracy: {100 * test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
